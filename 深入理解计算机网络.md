第一章：进制
二进制转换为十进制：二进制整数部分的一般表现形式为：bn-1…b1b0（共n位）：bn-1×2n-1+ bn-2×2n-2…+b1×21+b0×20，八进制十六进制类似
十进制转换为二进制：采用“除2逆序取余”法（采用短除法进行）。也就是先将十进制数除以2，得到一个商数（也是下一步的被除数）和余数；然后再将商数除以2，又得到一个商数和余数；以此类推，直到商数为小于2的数为止。然后从最后一步得到的小于2的商数开始将其他各步所得的余数（也都是小于2的0或1）排列起来（俗称“逆序排列”）就得到了对应的二进制数。
十进制小数转换成二进制的方法：十进制小数转换为二进制的方法是采用“乘2正序取整”法。也就是用2乘十进制小数，得到一个积，然后将积的整数部分取出作为相应步骤得到的整数；再用2乘余下的小数部分，又得到一个积；然后再将这个积的整数部分取出；以此类推，直到积中的小数部分为零，或者达到所要求的精度为止；最后把各步取出的整数部分（仅需要各步得到的整数部分，不需要最后没有取整的小数部分）按正序排列起来，即先取的整数作为二进制小数的高位，后取的整数作为低位。
0.125和0.625最后的二进制值分别为（0.001）2和（0.101）2（注意，一定要记得在整数部分加上“0.”，因为十进制小数转换成二进制后仍是小数）。
十进制整数转换为八进制整数采用“除8逆序取余”的方法，直到所得的商小于8，然后把余数（包括最后一步中得到的小于8的商数）按逆序排列即可；十进制小数转换为八进制小数是采用“乘8正序取整”法，直到所得到的积小数部分为0，或者在规定的精度范围内，然后把所得到的整数正序排列起来即可。
八进制转换为二进制：将每1位八进制数直接用相应的3位二进制来表示；二进制数转换成八进制数的方法是：以小数点为边界，整数部分向左，小数部分向右将每3位二进制分成一组，若不足3位则用0补足3位；然后将每一组二进制数直接用相应的1位八进制来表示。
八进制与十六进制的相互转换最好的方法就是先把其中一个转换成二进制，然后再把所得到的二进制转换成另一个进制的数。
二进制四则算法运算：与10进制一致
二进制逻辑运算：
“与”运算又称逻辑乘，用符号“.”或“∧”来表示。运算法则如下：0∧0 = 0 0∧1 = 0 1∧0 = 0 1∧1 = 1；仅当两数的对应位均为1时结果才为1
“或”运算又称逻辑加，用符号“+”或“∨”表示。运算法则如下：0∨0 = 0 0∨1 = 1 1∨0 = 1 1∨1 = 1；仅当两数的对应位均为0时结果才为0
“非”运算就是逐位求反的运算，其运算法则为：“0”的反值为“1”，“1”的反值为“0”，也就是“0”与“1”互为反。注意：“非运算”只是针对一个二进制数进行的
当两个参加“异或”运算的二进制数对应位相同时运算结果为0，不同时运算结果为1
补码知识点：
“无符号数”就是二进制数的每一位都代表对应位的数值；而在“有符号数”中规定最高位用来表示数据符号，其中1代表负，0代表正，这样一来机器数本身就不等于真正的数值了。例如有符号数10000101，其最高位1代表负，所以余下的“0000101”才是数值本身，所以其真正数值是-5，而如果是无符号数，则10000101所代表的是133。为区别起见，把带符号位的机器数所对应的真正数值称为机器数的“真值”
“字长”是指计算机一次可处理的二进制数的码位长度，是计算机进行数据存储和数据处理的运算单位。如我们通常所指的32位处理器，就是指该处理器的字长为32位，也就是一次能处理32位二进制数。通常称16位是一个字，32位是一个双字，64位是两个双字。
人们约定在一个二进制数前用第一位（最高位）来表示符号，即1表示负，0表示正，这就是最初“原码”的概念。
原码的表示形式是用方括号下面加上一个“原”字下标来区别的，如[+3] 原= 00000011，[-3]原= 10000011。
原码的设计很不错，至少可以成功地区分出二进制数的正与负了，但是这种方法仍有一些局限性，那就是原码在加、减法运算中不方便，符号位需要单独处理、单独判断。同为正数的加、减是没什么问题的，可是异号相加、减时就存在问题了
补码规则：正数的补码和原码相同；负数的补码是通过先把除符号位外其他各位取反，再在末位（最低位）加1得到的。这样，我们只要让减数通过一个求反电路，再通过一个+1电路，然后再通过加法器就可以实现减法运算了。
其实这里涉及一个计算机运算中“模”的概念。我们把一个计量单位称为模或模数。例如，时钟是以十二进制进行计数循环的，即以12为模。在时钟上，时针加上（正拨）12的整数倍或减去（反拨）12的整数倍，时针的位置不变。例如，14点钟在舍去模12后，成为（下午）2点钟（14=14-12=2）；从0点出发逆时针拨10格即减去10小时，也可看成从0点出发顺时针拨2格（加上2小时），即2点（0-10=-10=-10+12=2）。因此，在模12的前提下，-10可映射为+2。
同理，计算机的运算部件与寄存器都有一定字长的限制，因此它的运算也是一种模运算。如果字长为8，则当计数器计满8位也就是256个数后会产生溢出，又从头开始计数。产生溢出时的那个量就是计数器的模。显然，8位二进制数的模数为2的8次方，即256。在计算中，两个互补的数称为“补码”，这就是“补码”表示形式诞生的由来。
正数的原码、反码和补码都是一样的，而负数的这三种表示形式就不一样了，负数的反码是对原码中除符号位外的其他各位取反，而负数的补码是再对其反码加1，也就是先对其原码中除符号位外的其他各位取反，然后再在最低位加1。
补码的加法运算法则如下：[X＋Y]补= [X ]补＋[Y]补
补码的减法运算法则如下： [X－Y]补=[X]补＋[-Y]补
该公式表明，求两个机器数的差值（如[X-Y]补）的补码，可以通过求被减数的补码（如[X]补）与减数的负值的补码（[-Y]补）的和得到。[-Y]补是对减数进行求负操作，求负的规则是全部位（含符号位）取反后再加1（实际上也是分别对符号位和真值位进行求反，因为正数与负数的符号也正好相反）。
第二章：计算机网络概述
计算机网络硬件系统就是指计算机网络中可以看得见的物理设施，包括各种计算机设备、传输介质、网络设备这三大部分。
计算机网络通信和应用软件就是指安装在终端计算机中，用于计算机网络通信或应用的计算机程序
通信协议类型分为IBM令牌网络、分组交换网络、以太网协议局域网、TCP/IP协议网络等；按管理模式则可分为对等网和C/S（客户机/服务器）网络；按不同传输介质则可分为同轴电缆网络、双绞线网络、光纤网络、WLAN无线网络、卫星网络、微波网络等；按传输方式来分又可分为点对点网络和广播网络；按所覆盖的地理范围又可分为局域网、城域网和广域网；
第三章：计算机网络体系结构
OSI/RM体系结构是第一个标准化的计算机网络体系结构。它是针对广域网通信（也就是不同网络之间的通信）进行设计的，将整个网络通信的功能划分为七个层次，由低到高分别是物理层（Physical Layer）、数据链路层（Data Link Layer）、网络层（Network Layer）、传输层（TransportLayer）、会话层（Session Layer）、表示层（Presentation Layer）、应用层（Application Layer），如图3-2所示。但任何广域网其实都是由多个远程局域网连接而成的，所以在OSI/RM中不仅包括了广域网中不同局域网间通信的功能层次（上面五层），也给出了局域网内部通信所必需的两个层次（最下面两层）。
OSI/RM低四层（从物理层到传输层）定义了如何进行端到端的数据传输，也就是定义了如何通过网卡、物理电缆、交换机和路由器进行数据传输；而高三层（从会话层到应用层）定义了终端系统的应用程序和用户如何彼此通信，也即定义了如何重建从发送方到目的方的应用程序数据流。
无论是哪种划分方式，OSI/RM的每一层都要完成特定的功能，每层都直接为它的上层提供服务，同时又调用它的下层所提供的服务。所有层次都互相支持，在发送端网络通信是自上而下进行的（也就是自上而下调用服务），在接收端网络通信是自下而上（也就是自下而上提供服务）进行的，但双方必须在对等层次上进行通信（这就是对等通信原理，具体将在本章后面介绍）。当然并不是每一通信都需要经过OSI的全部七层，要视具体通信的类型而定，有的甚至只需要双方对应的某一层即可。如物理层中的物理接口之间的转接，以及中继器与中继器之间的连接就只需在物理层中进行即可。而网络层中的路由器与路由器之间连接则只需经过自网络层以下的三层即可。
TCP/IP协议体系结构只划分了四层，从高到低分别是：应用层（Apllication Layer）、传输层（Transport Layer）、网际互连层（Internet Layer，又称互联网层）和网络访问层（Network AccessLayer，又称网络接入层、网络接口层或者主机-网络层）。虽然只有四层，但它却包含了OSI/RM中的所有七层的功能，同样包括了局域网和广域网通信所需要的全部功能。
把原来的“物理层”和“数据链路层”这两层结构合并为一层，即网络访问层，它提供局域网中的功能；合并了原来OSI/RM中的最高的三层，成为新的应用层。因为事实上，在OSI/RM中会话层和表示层的功能都非常单一，完全可以合并到应用层之中。其他两层，“传输层”与OSI/RM中的功能划分是一样的，而网际互连层也与OSI/RM的网络层实际上是一样的，只不过名称不一样而已。但要注意的是，这里仅是从功能划分上来说的，实际上这两个体系结构是存在相当大差异的。因为OSI/RM是开放型的标准，所以适用于所有类型网络设计参考，而TCP/IP协议体系结构是专门针对TCP/IP网络的，各种通信协议和功能实现原理更加具体。
物理层是OSI/RM以及其他所有计算机网络体系结构的最底层，为所有网络/数据通信提供物理的通信线路。物理层是用来构建计算机网络通信和数据传输的通道的，相当于日常交通网络中的各种道路，如公路、铁路和航线，它们是我们出门旅行必须要依靠的基础设施。
数据链路层为同一局域网内部的网络/数据通信提供点对点的数据传输通道，通过MAC地址寻址把数据转到目的节点，可以理解为我们的市内公路+交通法规。之所以只能理解为市内公路，是因为在各个网络中的数据链路层间的通信仅可以在同一网段内进行；之所以还要加上“交通法规”，是因为数据链路层所提供的不再是物理线路，而是在物理层的物理线路基础之上，通过数据链路层协议（相当于市内交通法规）构建的，可真正用于数据传输的虚拟数据传输通道，但这样的虚拟数据传输通道也只能在同一网段内进行数据转发。
OSI/RM中的网络层（或TCP/IP协议体系结构中的“网际互连层”）为不同网段之间的数据转发提供路径选择，通过IP地址（也可以是其他网络层地址，要视具体网络类型而定）把数据包转发到目的节点，可以理解为交通网络中的车站、机场、码头
传输层”是在下面三层构建的网络平台基础上专门为通信双方构建端对端（不是点对点）的数据传输通道，使通信双方就像直接进行数据传输一样。这个端对端传输通道是可以跨网络的，这与数据链路层所构建的仅用于局域网内部的点对点传输通道是不同的。
会话层为具体的用户应用建立会话进程（每个应用都有一个会话进程），这个过程是一个用户网络应用的协商过程，相当于车站、机场或码头中总调度人员所从事的调度工作。表示层是对用户网络应用数据的具体解释，包括在网络通信时可采用的信息格式、可采用的加密方式，相当于车站、机场、码头中发送每一班次汽车、火车、轮船的具体文件，包括所采用的车型、机型、船型，以及所负责的运输公司、交接人员名单等内容。
应用层是用户进行具体网络应用的层次，是具体网络应用的体现者。应用层负责接受用户的各种网络应用进程的调用，相当于车站、机场和码头的负责人负责接受乘客运输的调度，确定具体班次的发送时间和要完成的任务。负责人一声令下，下面的所有相关工作人员都得围绕他的指令进行准备。应用层也一样，只要网络用户有需要，通过相应的网络应用软件就可以发出相应的指令，然后通过应用层相关的通信协议来接收，并向它的下面各层依次传达并使其执行具体的网络应用指令，进而完成整个网络应用任务。
“物理层”是以最原始的“比特”（bit）流格式传输的，或者说物理层的PDU就是“比特”。“数据链路层”的传输单位是“帧”（frame），一个帧包括多个比特，但一个帧的大小必须是一个整数字节。不同协议的帧大小也不一样。一个帧其实也就是一个DPDU（数据链路协议数据单元）。“网络层”的传输单位是 “分组”（或者“包”，paket），一个分组又可以包括多个帧，分组大小也要根据不同协议而定，一个分组其实也就是一个NPDU（网络协议数据单元）；传输层比较特殊，OSI/RM体系结构中是直接以TPDU（传输协议数据单元）为单位的，而在TPC/IP协议体系结构中，TCP是以数据段（segment）为单位进行传输的，UDP是以数据报（datagram）为单位进行传输的。在会话层、表示层和应用层中是以具体的数据报文为单位进行传输的。以上各层的数据传输单位如图3-9所示。如果是其他网络体系结构（如TCP/IP协议体系结构、局域网体系结构），各层上传输的数据格式也是一样的，不同的只是少了一些层次而已。
在整个数据传输过程中，数据在发送端时经过各层时都要附加上相应层的协议头和协议尾（仅数据链路层需要封装“协议尾”）部分，也就是要对数据进行协议封装，以标识对应层所用的通信协议。“协议头”是用来封装本层PDU的，“协议尾”则代表本层封装的结束。如在我们常见的以太局域网中传输的帧都会封装对应的数据链路层—以太网协议，其中就包括MAC子层协议头和LLC子层协议头，具体将在第6章介绍。图3-10中左边箭头所示的顺序就是OSI/RM各层的数据封装流程，其中的AH为应用层协议头，PH为表示层协议头，SH为会话协议头，TH为传输层协议头，NH为网络层协议头，DH为数据链路层协议头（物理层为最低层，传输的是最小单位的bit（比特），不需要再进行封装，所以没有“物理层头”），DT为数据链路层协议尾。
在数据的接收端，数据是由低层向高层传输的，这样当数据到达某一层后，就会去掉对应下层的协议头和协议尾部分，这个过程就是一个解封装的过程，是前面协议封装的逆过程，如图3-10中右边箭头所示的顺序。因为上层并不需要了解它的下层服务，所以当包或帧送到某一层时就会把用来标识它下一层的协议头和协议尾去掉，还原该包或帧在发送端对应层时的包或帧内容。其实加上协议头的作用可以理解为在发送端要一层层地加上一个指明到达下层地址的信封，而在接收端则要一层层地拆开信封，以获取向上层传输的地址信息，使数据能继续向上层传输。
第四章物理层
在计算机网络中传输的只能是二进制的数据，所以为了传输这些信息，首先需要将各个字母、数字、语音、图形或图像用二进制代码来表示，这就是我们通常所说的“信息编码”
数据有模拟数据和数字数据之分。模拟数据是通过连续取值得到的数据，如我们打电话时的通话语音，还有以前经常看到的模拟电影、模拟电视所用的数据都是属于模拟数据。而“数字数据”是把模拟数据离散、量化为二进制方式时取得的数据，如我们存放在计算机中的所的文件、图片、图像和软件等，以及我们现在经常看到的数字语音、数字电影、数字电视等所用的数据都属于数字数据。在计算机磁盘中存放在的必须是数字数据，而模拟数据通常存放在磁带、胶带中。
信号”是“数据”在传输过程中电信号或光信号的表示形式，因为“数据”有“模拟数据”和“数字数据”两种类型，所以信号也有“模拟信号”和“数字信号”两种。
信道”就是通信双方物理链路（包括有线物理介质上的链路和无线介质上的链路）上通过物理层协议建立起来的数据传输通道。
同步传输中关键是要理解“同步”的含义。同步就是指通信双方在传输过程中是同步进行的（也就是接收端与发送端同时开始工作，并且接收端按数据的发送顺序进行接收），同步的依据就是双方有相同的时钟参考，能同时开始数据的发送和接收。
同步传输是一种以数据块为传输单位（通常是以“帧”为单位的），以相同的时钟参考进行数据传输的模式，因此又称为区块传输。
异步传输的关键也是异步这两个字，是指通信双方没有相同的时钟参考（也就是发送端和接收端不同时开始工作），但双方在数据传输速率上是同步的。即指每个字符之间是异步的，但一个字符内的每一位还是同步的。
第五章数据链路层
物理链路是指在物理层设备（包括传输介质、物理接口和收发器等）和相应物理层通信规程作用下形成的物理线路，是永久存在的，且是不可删除的（除非物理拆除）；逻辑链路则是通信双方在需要进行数据通信时，在数据链路层设备和相应的通信规程作用下建立的逻辑链路，可以是永远存在的（如局域网中的以太网链路），也可以不是永久存在的（如广域网中的链路），是否永久存在要视具体的数据链路层服务类型而定。
数据链路层就一层，而在局域网体系结构中是可细分为两个子层的，那就是逻辑链路控制（Logical Link Control，LLC）子层和介质访问控制（Medium Access Control，MAC）子层
从以上介绍可以得知，其实SAP每层所对应的“地址”，但是针对一个具体的网络通信（注意，这里特别说明一下不是数据通信）来说，不同层中的SAP数是不一样的。如物理层的PSAP只有一个（就是对应的物理接口），数据链路层的DLSAP也只有一个（就是对应物理接口的MAC地址）
从“MAC”的中文名称“介质访问控制”可以看出，MAC子层的最基本功能就是如何控制不同用户数据传输中对物理层传输介质的访问，其中包括介质访问时的寻址（这里是通过MAC地址进行的），以及解决可能发生的介质访问冲突（也就是我们通常听到的“仲裁介质的使用权”，即规定站点何时可以使用通信介质）
从“LLC”的中文名称“逻辑链路控制”可以看出，LLC子层的最基本功能就是负责数据链路层中逻辑链路（逻辑链路就是物理层信道中的物理链路在通过LLC子层协议作用后形成的虚拟链路）的控制，其中包括逻辑链路的建立和释放，控制信号交换、数据流量控制，解释上层通信协议传来的命令并且产生响应，以及克服数据在传送的过程当中所可能发生的种种问题，如数据发生错误、重复收到相同的数据、接收数据的顺序与传送的顺序不一致等。
总体而言，数据链路层（其实这里主要是针对LLC子层）的主要功能就是四个方面：数据链路管理、封装成帧、透明传输、差错控制。
总体上可把这些数据链路服务分为以下三类：有确认的面向连接服务、有确认的无连接服务、无确认的无连接服务。前者称为面向连接服务（Connection-orientedServce），后面两者称为无连接服务
如网络层中的X.25协议是面向连接的，而IP协议则是无连接的；传输层中的TCP协议是面向连接的，而UDP协议是无连接的。
大多数广域网中通信子网的数据链路层协议采用有确认的面向连接服务，如SLIP（串行线路协议）、PPP（点对点协议）、PPPoE（基于以太网的点对点协议）、HDLC（高级数据链路控制）协议
LLC子层的链路管理功能主要是针对前面所介绍的有确认的面向连接服务类型（主要应用于广域网中）。它包括三个主要阶段：链路建立、链路保持、链路释放。
通过前面的学习我们就已经知道，网络层传输的包（packet，又称分组），在数据链路层中传输的是“帧”（frame）。数据包到达数据链路层后加上数据链路层的协议头和协议尾就构成了一个数据帧。在每个帧的前部加上一个帧头部，在帧的结尾处加上一个帧尾部，把网络层的数据包作为帧的数据部分，就构成了一个完整帧。帧头和帧尾就是作为帧的起始和结束标志，也就是帧边界
由数据包封装成的数据帧其大小是受对应的数据链路层协议的MTU（最大传输单元）限制的，如以太网数据链路层封装网络层IP包的MTU值为1500字节（这是指帧中数据部分，也就是来自网络层整个数据分组，最大不能超过1500字节，但不包括帧头和帧尾部分）
几种常用的帧同步方法的基本同步原理：字节计数法、字符填充的首尾定界符法、比特填充的首尾定界符法、违法编码法
这是一种以一个特殊字符代表一个帧的起始，并以一个专门的字段来标识当前帧内字节数的帧同步方法。接收端可以通过对该特殊字符的识别从比特流中区分出每个帧的起始，并从专门字段中获知每个帧后面跟随的“数据”（Data）字段的字节数，从而可确定出每个帧的结束位置。
该同步方法是用一些特定的控制字符来定界一个帧的起始与结束，如IBM的BSC协议在每个数据块的头部用一个或多个同步字符“SYN”来标记数据块的开始；尾部用字符“ETX”来标记数据决的结束。图5-8所示的是要传输一个“ADFGJ”的字符串，在帧的头部加上了两个SYN控制字符，用于标识该帧的开始，在结束位置加了ETX控制字符，用于标识该帧的结束。
该帧同步方法是通过在帧头和帧尾各插入一个特定的比特串（如01111110）来标识一个数据帧的起始与结束，这个帧头、帧尾特定比特串称为帧标志符。
该帧同步方法是在物理层采用特定的比特编码方法时采用。例如，曼彻斯特编码方法，将数据“1”编码成“高-低”电平对（在半个码元处跳变，下同，具体参见4.4.2节），将数据“0”编码成“低-高”电平对。而高-高电平对和低-低电平对在数据比特中是违法的，因此可以借用这些违法编码序列来定界帧的起始与终止。
在数据链路层检测数据传输错误的方法一般是通过对差错编码进行校验来实现，常见的校验方法有奇偶校验码（Parity Check Code，PCC）、循环冗余校验（Cyclic Redundancy Check，CRC）两种。它们都统称为检错码（error-detecting code）
在接收端收完一帧数据后，向发送端发送回所接收到的完整数据帧，由发送端通过与原始发送的帧进行比较来判断接收端是否正确接收了对应帧。如果判断是出了错，则发送端向接收端发送一个DEL字符及相应的帧信息，提示接收端删除对应的帧，然后重发该帧；否则表示接收端已正确接收了对应的帧，不重发对应的帧。但对于在传输过程中完全丢失的数据就不能采用这种纠错方法了，因为接收端根本没有收到这帧数据，所以也就不会向发送端发回反馈信息，发送端自然就不能确认接收端是否正确接收了对应的帧。
通常在数据发送时引入计时器（Timer）来限定接收端发回反馈信息的时间间隔。当发送端发送一帧数据的同时启动计时器，若在限定时间间隔内没有收到接收端的反馈信息，即计时器超时（Timeout），则可认为传的对应帧已出错，或丢失，继而发送端知道要重新发送对应的数据帧。同时，为了避免同一帧数据可能被多次重复发送，引发接收端多次收到同一帧并将其递交给网络层的危险，采用对发送的帧进行编号的方法，即同一个帧的编号是一样的，从而使接收端能从帧编号来区分是新发送来的帧，还是已经接收但又重新发送来的帧，以此来确定要不要将重新接收到的帧递交给网络层。
“流量控制”包括两方面的含义：一是发送端的数据发送速度与接收端的数据接收速度要匹配，否则接收端来不及接收就会造成数据在传输过程中的丢失。这个很好理解，比如几个人站成一排传递货物时，如果中间有个人速度比较慢，而上面的人不断传来货物，肯定就会把来不及接收的货物放在地上（不进入正常的传递之中）。二是发送端的数据发送速度要与线路上的承载速率（与线路信道带宽有关）相匹配，否则也会造成数据在传输过程中的丢失。这个也很好理解，就像一条小河，上游来的水量很大，超过了小河所能承载的能力，这时上游来的水肯定就不会有原来那么大的流速（形成速率瓶颈），甚至可能会漫过小河河堤而流到外面。
在数据链路层中进行流量控制的方案有两种：一是基于反馈的流量控制方案，二是基于速率的流量控制方案。
ARQ差错控制方案仅需返回少量控制信息（接收端不必重传整个数据帧），便可有效地确认所发数据帧是否正确被接收。ARQ法有几种具体的实现方案，空闲重发请求（Idle RQ）和“连续重发请求”（Continuous RQ）是其中最基本的两种方案。
空闲重发请求方案又称停-等（Stop and Wait）法，该方案规定发送端每发送一帧后就要停下来，然后等待接收端发来的确认信息（这就是停-等的意思），仅当接收端确认（ACK）信息后才继续发送下一数据帧。如果收到的是否认（NAK）消息，表示接收端接收的数据有错，请求发送端重发。另外，在计时器超时时，发送端也会重发对应的帧。
1）发送端每次仅将当前数据帧作为待确认帧保留在缓冲存储器中，当发送端开始发送数据帧（如图5-11所示的data0）时，随即启动计时器。2）当接收端收到这个数据帧时，先利用帧中附带的检错码进行校验，确认无差错后，即向发送端返回一个确认信息（如图5-11a所示的ACK0、ACK1和图5-11b所示的ACK0）；当检测到该帧有错误时，向发送端返回一个否认帧（如图5-11b所示的NAK0），同时丢弃该帧。3）如果发送端在计时器中规定的时间内收到来自接收端的确认信息，即将计时器清零，清除缓存中的待确认帧，然后才开始下一数据帧（如图5-11a所示的data1）的发送；若发送端在规定时间内未收到来自接收端的确认信息（即计时器超时），则重发存放于缓冲器中的待确认数据帧（如图5-11b所示的data1）。
现在来打个与这里所介绍的空闲重发请求差错控制方案类似的比方。一个牙牙学语的小孩，你要他从1数到10。由于他非常小，对这十个数字记得并不牢，所以他会一个个地去数，而且每数完一个数，他都会停下来，抬起头望着你，等待你的点头，或者说“对”，然后他才继续往下数。你对他点头或者说“对”，就相当于你向他发回了一个确认消息。
连续重发请求方案是指发送端可以连续发送一系列数据帧（也不总是不断地发送，具体可以连续发送多少个帧，要视双方的缓存空间大小，即窗口大小而定），即不用等前一帧被确认便可继续发送下一帧，效率大大提高。当然，在这个连续发送的过程中也可以接收来自接收端的响应消息（可以是确认帧，也可能是否认帧），发送端同样可以对传输出错的数据帧（如接收端返回了否认帧，或者响应计时器超时的帧）进行重发
回退N帧策略因可以连续发送数据帧而提高了传输效率，但也有不利的方面，那就是在重发时必须把原来已正确传送过的数据帧再次发送，仅仅是因为这些数据帧之前的某个数据帧或确认帧发生了差错，这样又使传输效率降低。所以当通信链路的传输质量很差、误码率较大时，回退N帧策略就没什么优势了，因为这时可能经常要重传大量的数据帧。
XON/XOFF（继续/停止）是一种最简单的流量控制技术，主要适用于异步通信中，接收端通过使用特殊字符来控制发送端数据的发送。其基本思想是：当接收端认为不能继续接收数据时（也就是接收端的缓存空间满了或者接近满时），接收端会向发送端发送一个XOFF控制字符，当发送端收到对应的XOFF控制字符时就停止数据的继续发送；当接收端可以继续接收数据时，接收端会再向发送端发送一个XON控制字符，发送端收到这个控制字符后就知道可以恢复数据发送了，继续发送数据，一直这么循环下去。
“滑动窗口机制”中的“窗口”是指发送端和接收端的缓存空间大小；“滑动”的意思是指缓存空间中存放的未处理帧数是变化的，发送端在收到确认帧后会删除原来保存在缓存中的待重发帧，而接收端向网络层提交一个帧后也会删除原来保存在缓存中的帧。
面向字符的同步方法也称“字符填充的首尾定界符法”。在该同步方法中，数据帧中的数据都被看作字符序列（所以称之为面向字符的同步传输），所有的控制信息也都是字符形式（当然数据的表示形式还是二进制的比特流），每个数据块的头部用一个或多个同步字符SYN来标记数据块的开始；尾部用字符ETX来标记数据决的结束。
面向比特同步传输的通信协议中，最具有代表性的是IBM的SDLC（Synchronous Data Link Control，同步数据链路控制）协议、国际标准化组织ISO的HDLC协议，美国国家标准协会ANSI的ADCCP。
连接速率低：SLIP使用的线路速率一般介于1200bps和19.2kbps之间，远没有PPP的连接速率高（PPP最高可达128kbps）。不能自动分配IP地址：进行SLIP连接的通信双方必须先具备静态IP地址，不能在连接过程中动态分配IP地址。所以当时的SLIP通常应用于专线连接中，在拨号连接中也仅应用于固定IP地址方式的连接。
第六章介质访问子层
MAC子层是有线局域网体系结构和WLAN体系结构中数据链路层的一个子层。它有两个主要作用，一是用来寻址（这里是MAC地址），也就是寻找目的节点；二是用来解决网络中多个用户争抢共享物理介质或者共享信道的现象。
所谓点对点信道是指由两个没有经过任何中间设备（也就是两设备的接口是“背靠背”连接的）的节点（也就是通常所见的计算机网卡，或其他网络设备端口）间构成的信道
局域网（包括令牌网、以太局域网和WLAN等）中与接入的各种传输介质相关的问题都放在MAC子层来解决，而且MAC子层还负责在物理层的基础上实现无差错的通信。具体说，MAC子层的主要功能包括：MAC帧的封装与拆卸（这方面已在第5章有详细介绍了），实现和维护各种MAC协议（这是本章重点之一），比特流差错检测（这方面也已在第5章有详细介绍了），MAC寻址（这也是本章重点之一）等。
非-坚持中的“非”的意思就是指各站点不连续侦听总线介质是否空闲，即在发现介质忙时，先停止侦听，等过一段时间再来侦听。
1-坚持中的“1”有两层含义：一是指发现总线介质忙时一直持续不间断侦听，直到发现介质处于闲状态；二是在侦听到介质处于空闲状态后一定（也就是100%）发送数据。
理解P-坚持CSMA退避算法的关键就是理解其中的P，其是指侦听到介质空闲时发送数据的概率（小于1，也就是小于100%），就是指站点在发现介质空闲时可以立即发送数据的概率为P，也就是不一定（不是100%）发送数据，还有（1-P）概率是不发送数据。其目的就是为了避免与其他站点发生冲突。
CSMA/CD的介质访问控制原理包含四个处理内容：侦听、发送、检测、冲突处理，可以用以下几句话来概括：先听后说（“听”是指侦听，“说”是指发送数据，下同），边听边说；一旦冲突，立即停说；等待时机，然后再说。
目前说的以太网帧，通常都会认为其帧头和帧尾包括LLC帧头、MAC帧头和MAC帧尾这三部分。
DSAP ：目的服务访问点（Destination Service Access Point）字段，指示数据接收方的LLC子层的SAP，占1字节（8位）。在以太网中，该字段的值固定为十六进制的0xAA。SSAP：源服务访问点（Source Service Access Point）字段，指示数据发送方的LLC子层的SAP，占1字节（8位）。在以太网中，该字段的值也固定为十六进制的0xAA。控制：Control字段，用于指示数据链路层所用的服务类型，占1字节（8位）。在以太网中都是采用无连接服务，所以固定值为十六进制的0x03。
MDI子层是标准以太网络接口物理层中的最低层，直接负责处理网络接口与传输介质的连接，其实就是网络接口连接器。它定义了电缆、连接电缆的连接器，以及电缆两端的终端负载的特性。
AUI（Attachment Unit Interface，连接单元接口）相当于网络接口收发器上的电缆。它定义了将MAU与PLS子层相连的电缆的机械和电气特性，同时还定义了通过这个电缆所交换的信号的特性。AUI上的信号有4种：发送和接收的曼彻斯特编码、冲突信号和电源信号。
PLS（Physical Layer Signaling，物理层信号）子层为MAC子层服务，是在网卡中实现的（PMA子层和MDI子层是在收发器中实现的）。如果PLS子层与PMA子层不处在同一个设备中，则它通过AUI与MAU连接。从其名称可以看出，PLS子层的主要功能是对物理层信号的处理，具体包括以下两个方面：编码/解码：发送时将MAC子层来的串行数据编码为曼彻斯特编码，并通过收发器电缆发送给收发器；接收时，接收AUI发送来的曼彻斯特编码信号，并进行解码，然后以串行方式发送给MAC子层。载波侦听：确定介质是否空闲，然后把侦听到的载波侦听信号发送给MAC子层。
第七章网络层
网络层是从功能上定义的一个逻辑层次，与物理层和数据链路层有具体的设备支持一样，网络层也有具体的设备来完成其相关任务，最典型的就是我们常用的路由器（Router）。路由器就相当于连接不同城市公路的中转车站，起数据中转作用，如图7-1所示。每个路由器至少可连接两个网络，就像一个城市的中转车站可以连接多个城市内的交通一样。
网络层是OSI参考模型中的第三层（对应TCP/IP协议体系结构中的第二层—网际互连层），介于传输层和数据链路层之间。总的来说，网络层的主要作用是实现两个网络系统之间的数据透明传送，具体包括路由选择、拥塞控制和网际互连等。网络层是端到端（也就是网络与网络之间）网络通信的最低层，在数据从数据链路层向传输层进行数据传输的通信中，起到构建一个中间通信子网的作用。它负责与它上面的资源子网（OSI/RM参考模型传输层及以上的四层）联系，是OSI/RM七层参考模型中面向网络通信的低三层（也即“通信子网”）中最为复杂、关键的一层。
局域网内部的用户访问也是需要寻址的，即通过MAC地址（又称硬件地址）进行。但MAC地址属于数据链路层地址，不能跨网进行寻址，那么在不同网络间进行访问时又是通过什么地址来进行寻址呢？那就是网络层的功能了。
在物理层传输的是一个个比特位（bit），在数据链路层中传输的是一个个以许多字节为单位的帧（Frame），在每个帧的帧头都有源节点的MAC地址和目的节点的MAC地址，局域网内部的寻址就是通过MAC地址进行的；而在网络层中传输的是数据包（Packet，又称分组），一个数据包是一个数据帧经过网络层协议重封装后得到的。每个数据包的包头都有源节点的IP地址和目的节点的IP地址，网络间的寻址就是通过IP地址进行的。在网络间的通信中，在网络体系结构中，数据是自上而下传输的（从网络层到物理层的数据单位依次是包、帧和比特），接收方是自下而上传输的（从物理层到网络层的数据单位依次是比特、帧和包）
网络层是为它的上一层—传输层服务的，并接受它的下一层—数据链路层所提供的服务。网络层的主要作用表现在以下几个方面。（1）屏蔽网络差异，提供透明传输（2）为网络间通信提供路由选择（3）数据包封装和解封装（4）拥塞控制
线路交换（Circuit Switching，又称电路交换）是最原始的数据交换方式，是在网络中利用可切换的物理通信线路直接连接通信双方所进行的一种数据交换方式。最常见的例子是电话交换系统和ISDN（Integrated ServicesDigital Network，综合业务数字网）系统。
线路建立：通过呼叫完成逐个结点的连接过程，建立起一条端到端的直通物理线路。数据传输：线路建立好后就可以直接在端到端的直通线路上传输数据。线路释放：数据传输完成后，由任一用户向交换网发出释放请求信令。该信令沿通路各结点传送，指挥这些结点拆除对应的链路，以释放信道资源。
存储–转发（Store-and-forward）从其名字就可以看出，这种数据交换方式是网络结点运用程序先将途径的数据流按传输单元（可以是报文或报文分组）接收并存储下来（同检验该数据单元的校验和），一个数据单元接收完后根据相关的路由算法选择一条合适的路由路径将数据转发出去，在逻辑（不是物理线路）上为数据流提供了传输通路。
通信子网中的结点是通信控制处理机（如路由器、三层交换机），其负责完成数据单元的接收、差错校验、存储、路选和转发功能。存储–转发数据交换方式的优点如下：通信子网中通信控制处理机具有路由功能，可以动态选择报文分组通过通信子网的最佳路径；可以有效地进行拥塞控制，提高端到端系统传输效率；数据单元在通过通信子网中的每个通信控制处理机时，均要进行差错检查与纠错处理，因此可以减少传输错误，提高系统可靠性；通过通信控制处理机可以对不同通信速率的线路进行转换，也可以对不同的数据代码格式进行变换。
报文交换（Message Switching）是指信息以报文（Message，完整数据的一个信息段）为单位进行存储–转发的一种数据交换方式。在报文交换方式中，报文是网络中交换与传输的数据单元，即站点一次性要发送的数据块，其包含了将要发送的完整的数据信息，其长短可能不一致，长度不限且可变。所谓存储–转发是当报文到达路由器后先存储起来，等待路由器分配资源再进行数据分组的转发。
报文交换的原理是用户发送的数据不是直接发送给目的节点的，而是先在中间结点上进行缓存（这类中间结点通常是由具有存储能力的交换机、路由器承担），然后再由中间结点在线路空闲时把数据发送出去。
分组交换（Packet Switching，也就是包交换）技术。在分组交换技术中有两大技术派系：一种是采用路由技术（也是目前比较普遍采用的一种交换方式），在要转发的数据包头部加上源节点和目的节点的IP地址，然后通过路由技术一级级地把数据转发下去。这种分组交换技术就是通常所说的数据报服务，其中的分组称为数据报（Datagram）。
另一种是不依靠路由技术，而是在进行数据分组转前先在源节点和目的节点间的所有路由器间建立一条虚拟的通信通道，然后再把数据分组从这个虚拟通道中转发到目的节点。这种分级交换技术就是虚电路服务，所建立的虚拟通道称为“虚电路”（Virtual Circuit，VC）。采用虚电路方式进行分组交换的典型实例就是通过ADSL拨号连接ISP网络（我们并不需要配置好到达ISP网络的路由），在配置时我们就要配置好ISP（Internet服务商）的VC值。
分组交换是结合报文交换和线路交换两种交换方式的优点而新开发的一种数据交换方式。分组交换也采用报文交换的存储–转发机制，但是规定了传输数据的单位长度，过长的报文被分成较小的单位（Packet，分组），依次发送。现在主要采用这种数据交换方式。
每个报文会有完整的发送信息，包括源和目的地址，但是如果把一个报文分成了几个分组，这些中间的分组肯定是不会包含有完整的发送信息的，那这些分组又是如何正确传输的呢？这时就要根据上节介绍的两种服务方式来选择了：通过数据报这种服务方式为每个分组都添加了报文号、分组号、目的地址、源地址和校验字段信息
采用虚电路这种服务方式的分组无须添加源和目的地址信息，但仍需要添加报文号、分组号信息，因为在发送任何分组之前，首先在发送主机和目的主机之间建立一条逻辑连接（也就是建立一条虚电路，无须进行路径选择），然后所有的分组都将按照顺序依次被发送到目的主机。在所有的分组都发送之后，虚电路将被拆除。每台主机可以和另一台主机建立若干个虚电路，每台主机也可以同时和若干台主机建立虚电路。
整个虚电路交换过程分为以下三个阶段：虚电路建立、数据传输与虚电路释放。
在这里首先要搞清楚什么是数据报。其实数据报就是在数据前部增加了源地址和目的地址信息字段的报文分段，可以作为独立的数据进行传输。因为每个数据报自身携带有足够的信息，其中包括源地址、目的地址、结点间的路由信息等，数据报的发送就是通过这些地址和路由信息来保证数据准确发送到目的节点的。一个结点接收到一个数据报后，根据数据报中的地址信息和结点所存储的路由信息，找出一个合适的出路，把数据报原样发送到下一个结点。
数据报操作方式的数据发送原理如下：1）当某个端系统要发送报文时，先将报文拆成若干个带有序号和地址信息的数据报，然后依次发给网络结点。2）各结点可根据数据报中所包括的地址和路由信息，选择不同的路由路径进行发送。另外，各个结点也可能随时根据网络的流量、故障等情况选择最佳路径。
在TCP/IP体系结构的网际互连层，最重要的协议就是IP协议簇。目前主流的IPv4协议簇中包括了三个协议：IP（Internet Protocol，因特网协议）、ARP（Address Resolution Protocol，地址解析协议）、ICMP（Internet Control Message Protocol，因特网控制消息协议）。IPv6协议簇中包括了四个协议：IPv6、ICMPv6、ND（Neighbor Discovery，邻居发现）协议和MLD（Multicast Listener Discover ，组播侦听器发现）协议。
IP协议的主要功能就是把数据报在互连的网络上传送，将数据报在一个个IP模块间传送直到传送到目的模块。网络中每个主机和网关上都有IP模块。数据报在一个个模块间通过路由处理网络地址传送到目的地址。
（1）寻址（2）数据报的封装（3）分段与重组
IPv4地址已经变得相当缺乏，时至今日全球几乎都无IP地址可分了，这大大影响了计算机网络的发展，也严重不适应当前移动互联网、物联网等新兴互联网技术的发展和普及。尽管我们一直在采用像NAT（Network AddressTranslation，网络地址转换）、VLSM（Variable Length Subnet Mask，可变长子网掩码）、CIDR（Classless Inter-Domain Routing，无类域间路由）这类可以更加充分使用现有公网IP地址的技术，但仍然很难满足从企业到个人的新兴互联网应用需求，于是采用新的IPv6协议的呼声在全球范围内日益高涨。
ARP（Address Resolution Protocol，地址解析协议）是将IP地址解析为以太网MAC地址（或称物理地址）的协议。
1）如果主机A不知道网关的MAC地址（也就是在主机A的ARP表中没有网关对应的MAC地址表项），则主机A先在本网段中发出一个ARP请求广播，ARP请求报文中的目的IP地址为网关IP地址，代表其目的就是想获得网关的MAC地址。如果主机A已知网关的MAC地址，则略过此步。2）网关收到ARP广播包后同样会向主机A发回一个ARP应答包。当主机A从收到的应答报文中获得网关的MAC地址后，在主机A向主机B发送的原报文的目的MAC地址字段填上网关的MAC地址后发给网关。3）如果网关的ARP表中已有主机B对应的MAC地址，则网关直接将在来自主机A的报文中的目的MAC地址字段填上主机B的MAC地址后转发给主机B。4）如果网关ARP表中没有主机B的MAC地址，网关会再次向主机B所在网段发送ARP广播请求，此时目的IP地址为主机B的IP地址，当网关从收到来自主机B的应答报文中获得主机B的MAC地址后，就可以将由主机A发来的报文重新在目的MAC地址字段填上主机B的MAC地址后发给主机B。
ICMP是（Internet Control Message Protocol）Internet控制报文协议。它是IPv4协议簇中的一个子协议，用于在IP主机、路由器之间传递控制消息。控制消息是指网络通不通、主机是否可达、路由是否可用等网络本身的消息。这些控制消息虽然并不传输用户数据，但是对于用户数据的传递起着重要的作用。
但与ARP协议不同，ICMP依靠IP协议来完成其任务，所以ICMP报文中要封装IP头部。它与传输层协议（如TCP和UDP）的目的不同，一般并不用来在端系统之间来传送数据，不被用户网络程序直接使用，除了像Ping和tracert这样的诊断程序。
ICMP报文包含在IP数据报中，IP报头在ICMP报文的最前面。一个ICMP报文包括IP报头（至少20字节）、ICMP报头（至少8字节）和ICMP报文（属于ICMP报文的数据部分）。
路由（Routing）是把信息从源节点通过网络传递到目的节点的行为，简单地讲路由就是指三层设备从一个接口上收到数据包，根据数据包的目的地址进行定向，并转发到另一个接口的过程。但在这条路由路径上，至少需要遇到一个中间结点，那就是提供路由功能的设备，如路由器和三层交换机。路由与桥接对比的主要区别在于，桥接发生在OSI参考协议的第二层（链接层），连接的是同一网络或同一子网的不同网段，而路由发生在第三层（网络层），连接的是不同网络或不同子网。
路由功能的实现是依靠路由器或三层交换机中的路由表进行的。路由又分静态路由（Static Routing）和动态路由（Dynamic Routing）两大类。下面分别予以介绍。
路由算法（Routing Algorithm）是在给定一组路由器及连接路由器链路的情况下，找出一条从源节点到目标节点的最佳路径。通俗地讲，就是把路由器选择最佳路径的策略称为路由算法，是路由器的关键功能所在。为了完成这项工作，在路由器中需要收集和保存着各种与传输路径的相关数据，如拓扑结构、端口度量、端口速率等，然后根据相应的路由算法生成一个个路由表（RoutingTable）表项，在数据包转发时提供路由选择。
第八章IP地址和子网
OSI/RM的网络层和TCP/IP协议体系结构的网际互连层最重要的一个协议就是IP协议，目前正处于IPv4和IPv6这两个版本交接、过渡时期
IPv4使用32位（4字节）地址，因此整个地址空间中有4 294 967296（232）个地址，也就是近43亿个地址。不过，其中一些地址是为特殊用途保留的，如局域网专用地址（约1800万个地址）和组播地址（约2700万个地址），这样一来可直接在广域网上使用的、路由的公网IP地址数量就更加少了。
公网IP地址是指可以在广域网上直接使用，直接被路由（也就是可以被指路径查找到），并需向IP地址管理机构申请、注册、购买，且全球唯一（不存在多个用户拥有、使用相同的公网IP地址的情况）的IPv4地址。打个比方来说，公网IP地址就相当于我们公民的身份证号，每个身份证号都是全国唯一，并且通过这个身份证号，就可以查到我们的基本信息，找到我们。公网IP地址直接分配给互联网上的主机、服务器或其他设备，可以通过它在全球范围内找到对应的主机、服务器和设备。如各大企业网站通常都是直接使用公网IP地址的。
私网IP地址是指仅可以在各用户自己的局域网内部使用，且不同用户可以重复使用，无须向IP地址管理机构申请、注册，也无须购买的IPv4地址。私网IP地址就相当于我们企业内部的员工编号，仅在企业内部有用，不能通过这个员工编号来在全国范围找到我们。
IPv4地址在计算机内部是以二进制形式表示的，每个地址都有32位，由数字0和1构成。在这32位的二进制数中，其实每个8位之间并没有我们所看到的那个用来分隔各段的一个小圆点，只是为了方便我们自己阅读，在每个字节间用一个小圆点分隔。因为整个IP地址有32位，无论是书写还是记忆都不方便，于是我们在日常的IP地址管理中把这个32位长的二进制IP地址分段转换成对应的十进制，在每个字节间用小圆点分隔。引用某个IPv4地址时，可使用W.X.Y.Z的点分十进制表示形式，如192.168.1.10等
要想理解什么是子网掩码，就不能不先了解IPv4地址的构成。互联网是由许多小型网络构成的，每个网络上都有许多主机，这样便构成了一个有层次的结构。IPv4地址在设计时就考虑到地址分配的层次特点，将每个IP地址都分割成网络ID和主机ID两部分，以便于IPv4地址的寻址操作。那么IPv4地址的网络ID和主机ID各是多少位呢？如果不指定，在寻址时就不知道对应IPv4地址中哪些位代表网络ID、哪些代表主机ID，这就需要通过这里所说的子网掩码来实现了。
与二进制IPv4地址相同，子网掩码也由1和0组成，且长度也是32位，我们也可以把它分成网络ID和主机ID两部分，且各自的长度与IPv4地址的网络ID和主机ID部分对应相等。但子网掩码中的网络ID部分全是1，1的数目等于网络ID的长度；主机ID部分全是0表示，0的数目等于主机ID的长度。如图8-3所示的是一个网络ID长度为16的子网掩码示例。这样做的目的是为了在寻址过程中使子网掩码与对应的IPv4地址做逻辑与运算时用0遮住IPv4地址中原主机ID部分（因为0与任何数相与结果都是0），而不改变原网络ID部分（因为1与任何数相与的结果都不改变原来的值），这样就一来就可以很容易确定对应目的IPv4地址所在的网络了，确定了网络，也就确定了主机，因为在IPv4地址中除了网络ID
子网掩码一旦设置，对应IPv4地址中的网络ID和主机ID部分就固定了。
与IPv4地址一样，子网掩码也可以转换成点分十进制形式。根据子网掩码格式可以发现，子网掩码有0.0.0.0；255.0.0.0；255.255.0.0；255.255.255.0；255.255.255.255五种，其中0.0.0.0掩码代表任意网络的掩码，如我们在设置默认路由时，不仅IP地址为0.0.0.0，子网掩码也为0.0.0.0；A类地址的默认子网掩码为255.0.0.0；B类地址的默认子网掩码为255.255.0.0；C类地址的默认子网掩码为255.255.255.0；而255.255.255.255可以看作是单一主机网络，代表这个网络就这一个IPv4地址，在配置ACL（访问控制列表）时，如果控制的是一台主机，则对应的子网掩码也为255.255.255.255。
IPv4地址共有232个，最初把一个IPv4地址分成两部分：“网络识别码”在地址的最高一个字节中，“主机识别码”在剩下的部分中。这样划分的话，就使得最多只能分配给256个网络，显然这样是远远不够的。
在分类中规定，A类IPv4地址中网络ID的最高位固定为0，后面的7位可变。这样一来，A类网络的总数从256（28）个减少到128（27）个。但实际上可用的只有126个，即整个IPv4地址中可构建126个A类网络，因为网络ID为0和127的A类网络不可用的。网络ID全为0的地址为保留地址，不能被分配；而网络ID为01111111（相当于十进制的127）的地址专用本地环路测试（也就是通常所说的环路地址），也是不能分配的。也就是凡是以0或者127开头的地址是不能分配给节点使用的。
又因为A类IPv4地址中主机ID有24位，所以可用的主机ID数，也就是可以每个A类网络中拥有的IPv4地址数为166 777 216（224）。但主机ID全为0的地址为网络地址，而主机ID全为1的地址为广播地址，不能分配给主机使用，所以实际上可用的地址数为166 777 214（166 777 216–2）。A类网络中可以构建的网络数最少，但每个网络中拥有的地址数是最多的，也就是可以构建的网络规模最大，适用于大型企业和运营商。
B类IPv4地址的网络ID的最高两位固定分别为1、0，后面的14位可变。由此可知B类网络的总数从65 536（216，也可写成256×256）减少到16384（64×256）个；B类IPv4地址中主机ID为16位，所以可用的主机ID数，也就是每个B类网络拥有的IPv4地址数为65 536（216）个。同样因为主机ID全为0的地址为网络地址，而主机ID全为1的地址为广播地址，不能分配给主机使用，所以实际上可用的地址数为65 534（65 536–2）
C类IPv4地址的网络ID的最高两位固定分别为1、1、0，后面的21位可变。由此得知C类网络总数从166 777 216（224，也可写成256×256×256）个减少到2 097 152（32×256×256）个。C类IPv4地址中主机ID仅为8位，所以可用的主机ID数，也就是每个C类网络拥有的IPv4地址数为256（28）个。同样因为主机ID全为0的地址为网络地址，而主机ID全为1的地址为广播地址，不能分配给主机使用，所以实际上可用的地址数为254（256–2）。
IP 组播技术有效地解决了单点发送多点接收的问题，实现了IP 网络中点到多点的高效数据传送，能够大量节约网络带宽、降低网络负载。还可以利用网络的组播特性方便地提供一些新的增值业务，包括在线直播、网络电视、远程教育、远程医疗、网络电台、实时视频会议等互联网的信息服务领域。
预留组播地址（又称永久组播地址）就是由IANA保留不分配给特定用户使用，仅为公用的组播路由协议分配使用的组播地址，地址范围为224.0.0.0～ 224.0.0.255。使用这些预留组播地址的组播协议包括IGMP（Internet组管理协议）、CGMP（Cisco组管理协议）、IGMP Snooping（IGMP侦听）和PIM（协议无关组播）等。使用这段组播地址的IP包不被路由器转发。
公用组播地址就是在全球范围内可以直接在互联网上使用的组播地址，就像前面介绍的公网单播IPv4地址一样。公用组播地址范围为224.0.1.0～224.0.1.255，也是由IANA为提出申请并付费的用户分配的。
临时组播地址就是由企业用户在本企业局域网内部使用的组播地址，地址范围为224.0.2.0～238.255.255.255，仅在本地局域网内有限，就像前面介绍的局域网IPv4地址一样。
本地管理组播地址也是保留使用的，专用于局域网内部组播测试，地址范围为239.0.0.0 ～ 239.255.255.255，仅在特定的本地网络范围内有效。
当网络层收到组播数据报文时，根据组播目的地址查找组播转发表，对报文进行转发。在私网中，组播是不需要在工作站上配置的，只需要在网络中的路由器或者支持组播协议的三层交换机上进行配置。私网工作站中被分配的组播地址都是224.0.0.1，就像环路地址127.0.0.1一样，无须另外配置。只要在路由器中启用了组播协议后就可以对应加入到组播组中。公网中，工作站组播地址选择224.0.1.0 ～ 238.255.255.255范围中的一个即可。
E类IPv4属于IANA保留地址，不分配给用户使用，地址段范围为240.0.0.0～ 247.255. 255.255，其特征是最高5位分别是1、1、1、1、0，如图8-9所示，也就是有27位是可变的。
为了解决这种可用网络数太少的问题，同时提高IP地址有有效利用率，于是出现了一种称为VLSM（Variable Length Subnet Masking，可变长子网掩码）的技术，该技术可以使网络中IPv4地址的子网掩码所占位数不是固定的，如子网掩码位数可以不是以字节为单位的整数，如12、13、14、25、26、28、等均可。因为子网掩码位数不固定了，也就不能再依据子网掩码来进行分类了，所以采用VLSM后形成的网络称为无类网络，而以前传统的A、B、C类网络则相对应地被称为有类网络或标准网络。而我们把在有类网络中通过VLSM技术改变子网掩码长度而划分的小网络称为子网。
这时你可能马上会问，VLSM能给我们带来什么好处？简单地说体现在三个方面：①用户可以根据网络规模大小选择拥有适当可用IPv4地址的IPv4地址段，这样可以减少IPV4地址的闲置和浪费，降低广播风暴产生的可能；②可以提高路由效率；③提高广域网中的网络安全。
网络地址是用来标识一个有类或无类网络的地址，是对应网络或子网的第一个IPv4地址，即主机ID部分全为0的IPv4地址；而广播地址则是一个有类或无类网络中的最后一个IPv4地址，即主机ID部分全为1的IPv4地址，可通过这个地址向对应网络或子网以广播方式发送数据包（也就是广播通信），让本地网络或子网的所有节点都可收到同一数据包。在一个对应网络或子网中，除了网络地址和广播地址这两个一头、一尾的地址外，中间其他的所有地址都是主机地址，它是可直接分配给主机使用的IPv4地址。
如在192.168.1.0/24网络中（有关地址前缀表示形式将在下节介绍），网络地址为192.168.1.0/24，广播地址为192.168.1.255/24，其他254个IPv4地址都是主机地址。如192.168. 1.0/26这样一个子网中，它的网络地址为192.168.1.0/26，而广播地址为192.168.1.63，而中间其他的62个IPv4地址都是主机地址。有关子网划分的方法将在本章后面介绍。
1）某个或某几个8位组值为0或者255的IPv4地址不一定就是网络地址或广播地址。不要一看到某个或者某几个8位组值全为0就认为是网络地址，也不要一看到某个或某几个8位组值全为1就认为是广播地址，具体还是要看主机ID部分是否全为0，或1。如1.1.0.0/8这个地址就不是网络地址，因为它是一个标准的A类网络。主机ID部分应该是后面的全部3字节（24位），现在只有最后2字节的值全为0，而第二个字节的值为1。1.1.0.0/8的网络地址是1.0.0.0/8。同样，1.1.1.255/8、1.1.255.255/8也不是广播地址，原因同上，只是这里的主机ID部分（也就是最后3字节，共24位）应该全为1（每个字节转换成十进制为255），但这里只有最后2字节的值全为1。
2）网络地址和广播地址中不一定是整个8位组的值为0或255。也不是所有网络地址的主机ID都是整个字节的十进制值为0，所有网络地址的主机ID都是整个字节的十进制值为255。这仅适用于标准的有类网络，因为有类网络中，都是用整个字节来划分网络ID和主机ID的，但在无类网络中，并不是这样的。
在子网划分类试题或者具体工网络程中不外乎两种情形：1）已知要划分的子网数和最大地址数，求子网掩码、子网地址范围、网络地址和广播地址，其基本计算步骤如下：a）根据所需的子网数和最大地址数确定划分子网后的新网络ID长度和新主机ID长度；b）根据新主机ID长度确定子网划分后各子网的地址块大小，由此可进一步确定各子网的地址范围、网络地址和广播地址；c）根据下面的公式得出划分子网后各子网共同的子网掩码。新子网掩码=原网络ID.新主机ID中各字节分别用256-各子地址块（各字节的值之间以小圆点分隔）2）已知子网地址前缀或子网掩码，求子网地址范围、网络地址和广播地址。其基本计算步骤如下：a）根据子网的地址前缀或子网掩码确定该子网地址块大小；b）根据地址块大小，可进一步确定该子网的地址范围、网络地址和广播地址；
NAT服务工作在路由器上（同时可工作在三层交换机或防火墙上），通常用于连接两个网络，通过把内部网络中的多个私网IPv4地址转换为合法的一个或多个公网IPv4地址，让使用非注册IPv4地址的私有IPv4网络全部或部分用户连接到Internet，或者允许Internet用户访问内部网络设备，如邮件服务器。
（1）无足够的公网IP地址可用时
（2）重构网络IP地址部署
（3）实现简单的TCP负载均衡
内部本地地址是指分配给内部网络主机的IP地址。这个IP地址是计算机操作系统，或诸如DHCP之类的服务进行分配的，但既可以是仅限于内部局域网使用的私有非注册IP地址，也可以是由ISP统一分配的注册IP地址。它们都是在内部网络使用的，通常是指非注册IP地址。
这是本地地址的另一种，与内部本地地址性质一样，是为外部网络主机分配的本地网络IP地址，是外部网络主机对内部网络用户呈现的IP地址。这个IP地址是计算机操作系统或诸如DHCP之类的服务进行分配的，但也既可以是仅限于内部局域网使用的私有非注册IP地址，也可以是由ISP统一分配的注册IP地址。通常是指专用网络使用的非注册IP地址。
全局地址是与本地地址相对应的IP地址，它是内、外部网络本地址转换后的IP地址的，是可路由的。全局地址其实是指在内、外网络中间架设的一个过渡性网络的IP地址。内、外部网络相互通信都需要先把对应的本地地址转换成对应的全局地址才能与对方网络进行通信。考虑到NAT路由器既有与像互联网这样连接局域网的情形，又有连接两个局域网的情形，所以全局地址也既可以是可供注册的公网IP地址，也可以是非注册的私网IP地址。但NAT的应用主要是内部局域网与Internet的连接，所以外部网络一般是Internet，这样，全局地址也就一般是公网注册IP地址了。
在私有网络中的计算机是使用内部本地地址（Inside Local Addresses）进行通信的，当它们需要与外部网络进行通信时，就需要为他们配置内部全局地址
第九章路由协议及工作原理
RIP（Routing Information Protocol，路由信息协议）是应用较早、使用较普遍的内部网关协议（Interior Gateway Protocol，IGP），适用于小型同类网络的一个自治系统（AS）内的路由信息的传递。RIP协议采用距离矢量（也就是用距离作为路由变量）路由算法，使用跳数（即Hop）来衡量到达目标地址的路由距离，且最大跳数值仅为15。
RIP路由器总是会每隔30s（这是默认值，可以修改，而且也可能与设置值有些偏差）通过UDP 520端口以RIP广播应答方式向邻居路由器发送一个路由更新包，包中包括了本路由器上的完整的路由表（除了被水平分割机制抑制的路由表项），用来向邻居路由器提供路由更新，同时用来向邻居路由器证明自己的存在。RIP的路由表中主要包括目的网络、下一跳地址和距离这三个字段
由于RIP协议主要用于小型网络，在20世纪80年代中期就已不能适应大规模异构网络的互连，一种互连功能更强大的路由协议—OSPF（OpenShortest Path First，开放式最短路径优先协议）就随之产生了
OSPF也是一个内部网关协议，用于单个自治体系（AS）的路由器之间。OSPF采用链路状态技术，路由器互相发送直接相连的链路信息和它所拥有的到其他路由器的链路信息。每个OSPF路由器维护相同AS拓扑结构的数据库。从这个数据库里，构造出最短路径树来计算出路由表。
（1）采用链路状态路由算法（2）可划分不同区域（3）有不同路由器角色（4）收敛性能更高
在一个广播性、多路访问的网络（例如Ethernet、TokenRing及FDDI环境）中，如果每个路由器都独立地与其他路由器进行LSU（Link StateUpdate Packet，链路状态更新包） 交换，以同步各自的LSDB，将导致一个巨大的流量增长。为了防止出现这种现象，同时使路由器保存的链路状态信息最少，OSPF在这类网络上选举出一个DR（Designated Router，指定路由器）和BDR（Backup Designated Router，备份指定路由器）。区域内那些既不是DR，也不是BDR的路由器称为DR Other。
DR和BDR也不是随便担当的，需要选举产生，就像我们在学校选正、副班长一样，也是要投票选举的。DR是通过接口优先级（Interface Priority）进行选举，最高优先级的路由器被选为DR，次高者被选为BDR；如果接口优先级相同，就按router-id进行选举，由最大到次大选举DR、BDR。
OSPF是一种典型的链路状态路由协议，默认情况下采用OSPF的每个路由器彼此交换并保存整个网络的链路信息，从而掌握全网的拓扑结构，并独立计算路由。划分区域后，OSPF路由器收集其所在网络区域上各路由器的连接状态信息，即链路状态信息，生成LSDB。然后OSPF路由器利用SPF路由算法独立地计算出到达任意目的地的路由。
这样在区域内的路由器中就只需要为数不多的区域内路由和一条指向ABR的默认路由即可，使区域内的路由表简化。而且无论区域外的路由如何变化，都不会影响到区域内路由器这个简单的路由表。这就是OSPF路由协议中“Stub Area”（末梢区域）的设计理念。
IS-IS（Intermediate System-to-Intermediate System，中间系统到中间系统）是一个链路状态内部网关协议（Interior GatewayProtocol，IGP），是OSI/RM协议栈中CLNS（Connectionless NetworkService，无连接网络服务）的一部分。
集成IS-IS是一个能够同时处理多个网络层协议（例如IP和CLNP）的路由选择协议。相反，OSPF只支持IP一种网络层协议，即OSPF仅支持IP路由，专为TCP/IP网络设计。集成IS-IS可以支持纯CLNP网络或纯IP网络，或者同时支持CLNP和IP两种网络环境，并为其提供路由功能。集成IS-IS协议经过多年的发展，已经成为一个可扩展的、功能强大、易用的IGP路由选择协议，并且在运营商网络中得到了更多的应用和部署，主要用来实现域内（也就是一个自治系统内）的IP路由选择。
ES-IS的英文全称为End System to Intermediate System RoutingExchange Protocol，翻译成中文就是终端系统到中间系统的路由交换协议，是由ISO开发，用来允许终端系统和中间系统进行配置和路由信息的交换，以推动ISO网络环境下网络层的路由选择和中继功能的操作。终端系统指用户设备，中间系统指路由器。它在CLNP网络中，就像IP网络中的ARP、ICMP一样，为终端系统与路由器间提供路由信息交换功能。
要正确理解IS-IS路由协议工作原理，首先要理解以下这些基本专业术语。（1）IS（Intermediate System，中间系统）就是TCP/IP网络中的路由器。它是IS-IS协议中生成路由和传播路由信息的基本单元。在本章下文中IS和路由器具有相同的含义。（2）ES（End System，终端系统）相当于TCP/IP网络中的主机系统。ES不参与IS-IS路由协议的处理，在ISO网络中使用专门的ES-IS协议定义终端系统与中间系统间的通信。（3）RD（Routing Domain，路由域）指多个使用IS-IS协议的路由器所组成的范围。（4）Area（区域）指IS-IS路由域的细分单元，IS-IS像OSPF一样允许将整个路由域分为多个区域。
第十章传输层
也许有人会说，传输层的主要作用就是为它的上层提供端到端的数据传输服务。那么，什么叫端到端服务呢？其实这里面包含两层含义：第一层含义是从物理的网络连接角度来讲的，即端到端是指网络通信的双方不是在同一链路上，不是点对点连接的；第二层含义是从虚拟的传输连接角度来讲的，即端到端是指在用户看来两端的连接是直接进行的（其实并不是这样的），屏蔽了核心网络结构和各种子网间的差异。
1）一开始，服务器调用Listen原语，使其处于监听状态，直到有客户来请求连接。2）当一个客户希望与该服务器进行会话时，它调用Connect原语，向服务器发送一个请求建立传输连接的CR TPDU。3）当该CR TPDU到达服务器时，服务器传输服务实体执行状态检查，看服务器是否正处于监听状态。如果是，则解除监听，并向客户端返回一条确认连接请求的CC TPDU。4）在这个CC TPDU到达客户端后，客户端获知服务器同意建立传输连接了，随后便通知客户端应用进程开始建立传输连接。5）传输连接建议好后，就可以正式发送DT TPDU了。任何一方都可以调用Receive原语，以等待另一方调用Send原语，发送数据。当一方接收到另一方发来的DT TPDU时，接收端会发送一个数据接收确认的DA TPDU。6）当不再需要一个连接时，传输用户必须将它释放，以便使两个传输实体内部的缓存空间有机会被重新使用。
所谓“三次握手”是指在建立连接时，发送端发送CR TPDU请求建立一个连接（第一次握手）；接收端收到CR TPDU后发送一个CC TPDU进行应答（第二次握手），在应答分组中宣告了自己的初始连接序列号；发送端收到应答分组后发送第一个DT TPDU，对接收端初始序列号进行确认（第三次握手）。这样，一个连接才能建立起来，并且双方可以使用不同的起始序号。整个三次握手过程如图10-23所示，简单描述如下（在TCP/IP体系结构中的TCP传输连接的建立也采用“三次握手机制”，具体内容将在本章后面介绍）。
OSI/RM体系结构的传输连接释放也采用三次握手协商方式（TCP/IP体系结构中的TCP传输连接释放是采用“四次握手机制”的，具体内容将在本章后面介绍），其中也分“正常释放连接”和“非正常释放连接”两种情况。“非正常释放连接”又包括以下3种情况：最后的确认TPDU丢失、应答TPDU丢失、应答及后续释放请求DR丢失。本节以对称释放方式为例进行介绍。
TCP是TCP/IP体系结构中最主要的传输层协议，在功能上与本章前面介绍的OSI网络中的TP4类传输层协议类似，但TCP只能提供面向连接的传输服务，而且TCP还具有以下主要特性：
（1）面向连接的传输协议（2）仅支持单播传输（3）提供可靠的交付服务（4）传输单位为数据段（5）仅一种TPDU格式（6）支持全双工传输（7）TCP连接是基于字节流的，而非报文流（8）每次发送的TCP数据段大小和数据段数都是可变的
TCP通过数据段的交互来建立连接、传输数据、发出确认、进行差错控制、流量控制及关闭连接。整个TCP数据段也分为“数据段头”和“数据”两部分（这也是绝大多数报文封装的方式），所谓“数据段头”就是TCP为了实现端到端可靠传输而加上的TCP控制信息，而“数据”部分则是指由高层（即TCP/IP体系结构中的“应用层”）来的用户数据。但由于TCP中只有一种TPDU格式，所有类型的数据段格式都统一在如图10-34所示的TCP数据段格式中，不同类型数据段是通过其中的多个控制位来实现的。
1）源端口和目的端口源端口和目的端口分别代表呼叫方和被叫方的TCP端口号，各占16位。一个端口与其主机的IP地址就可以完整地标识一个端点了，也就是构成了前面所说的套接字（Socket）。
2）序号（Sequence Number）序号指TCP数据段中的“数据”部分（不包含“数据段头”部分）的第一个字节的编号，占32位。在一个TCP连接中，传送的数据字节流中的每一个数据字节都要按顺序进行编号，在“数据段头”中标识的只是每个数据段的第一个数据字节的编号（3）确认号（Acknowlegment Number）确认号指期望接收到对方下一个数据段中“数据”部分的第一个字节序号，占32位。注意，“确认号”不是代表已经正确接收到的最后一个字节的序号。例如，主机B已收到主机A发来的一个数据段，其序号值是101，而该数据段的长度是100字节。这表明主机B已收到主机A前200个字节，下一个期望要收到的数据段的第一个字节的序号应该是201，于是主机B在给主机A发送确认数据段时要把“确认号”设置为201。
数
（4）数据偏移数据偏移指数据段中的“数据”部分起始处距离TCP数据段起始处的字节偏移量，占4位。其实这里的“数据偏移”也是在确定TCP数据段头部分的长度，因为“数据”部分是紧接着数据段头的。因为TCP数据段头中有不确定的“可选项”字段，所以数据偏移字段是非常必要。
（5）保留（Reserved）这是为将来应用而保留的6个比特位，目前应全设置为0。
（6）URGUrgent Pointer（紧急指针）控制位，指出当前数据段中是否有紧急数据，占1位，置1时表示有紧急数据。紧急数据会优先安排传送，而不会按照原来的排队顺序进行发送，相当于本章前面介绍OSI/RM传输层TPDU时所说的“加速数据”。
（7）ACKAcknowledgement（确认）控制位，指示TCP数据段中的“确认号”字段是否有效，占1位。仅当ACK位置1时才表示“确认号”字段有效，否则表示“确认号”字段无效，应用层实体在读取数据时可以不管“确认号”字段。
（8）PSHPush（推）控制位，指示是否需要立即把收到的该数据段提交给应用进程，占1位。当PSH位置1时要求接收端尽快把该数据段提交给应用进程，而置0时没这个要求，可以先缓存起来。
（9）RSTReset（重置）控制位，用于重置、释放一个已经混乱的传输连接，然后重建新的传输连接，占1位。当RST位置1时，释放当前传输连接，然后可以重新建立新的传输连接。
（10）SYNSynchronization（同步）控制位，用来在传输连接建立时同步传输连接序号，占1位。当SYN位置1时，表示这是一个连接请求或连接确认报文。当SYN=1，而ACK=0时，表明这是一个连接请求数据段（相当于本章前面介绍的OSI/RM TPDU中的CR TPDU）。如果对方同意建立连接，则对方会返回一个SYN=1、ACK=1的确认（相当于本章前面介绍的OSI/RM TPDU中的CC TPDU）。
（11）FINFinal（最后）控制位，用于释放一个传输连接，占1位。当FIN位置1时，表示数据已全部传输完成，发送端没有数据要传输了，要求释放当前连接，但是接收端仍然可以继续接收还没有接收完的数据。在正常传输时，该位置0。
（12）窗口大小指示发送此TCP数据段的主机上用来存储传入数据段的窗口大小，也即发送者当前还可以接收的最大字节数，相当于本章前面介绍OSI/RM TPDU中的CDT（信用量分配），占16位。TCP的“窗口大小”字段与本章前面介绍的CDT一样是使用可变大小的滑动窗口协议来进行流量控制。
（13）检验和（Checksum）检验和是指对“数据段头”、“数据”和“伪头部”这三部分进行校验，占16位。“伪头部”包括源主机和目的主机的32位IP地址、TCP协议号（6），以及TCP数据段长度。
（14）紧急指针（Urgent Pointer）仅当前面的URG控制位置1时才有意义，它指出本数据段中为紧急数据的字节数，占16位。“紧急指针”字段指明了紧急数据的末尾在数据段中的位置。当所有紧急数据处理完后，TCP就会告诉应用程序恢复到正常操作。要注意的一点是，即使当前窗口大小为0，也是可以发送紧急数据的，因为紧急数据无须缓存。
15）可选项（Option）“可选项”字段是可选的，且长度可变，最长可达40字节。当没有使用该字段时，TCP头部的长度是20字节。它可以包括窗口缩放选项（WindowScale Option，WSopt）、MSS（最大数据段大小）选项、SACK（选择性确认）选项、时间戳（Timestamp）选项等。
在TCP/IP网络中，同样有端点的概念，但它并不是直接采用OSI/RM中的TSAP叫法，而是称为“套接字”（Socket），就像在TCP中仍然把所传输的数据称为“数据段”，而没有采用OSI/RM中的TPDU叫法一样。当然，需要说明的是，Socket并不能直接等同于TSAP，它们只是类似，实际上Socket只是利用了TSAP地址，因为在它所包括的一组参数中就有TSAP地址—端口。“套接字”最早使用于UNIX操作系统中，后来被广泛地应用于Windows和Linux系统中，成为了事实上的TCP标准。
（1）保留端口通常将0～1023号TCP端口保留，因此，这类端口也称为“常规端口”，或者“公认端口”（well-known port）。这些端口基本上都已固定地分配给了已知的网络应用协议，如HTTP（对应WWW服务）中的80号端口、Telnet协议中的23号端口、SMTP中的25号端口等。
动态分配端口的端口号一般都大于1024，它们没有分配给固定的网络应用服务，因此，可以动态地分配给任意网络服务应用程序使用。也就是说，在使用网络应用软件访问网络时，网络应用软件可以向系统申请一个大于1024的端口临时代表这个软件与传输层交换数据，并且使用这个临时的端口与网络上的其他主机通信。
注册端口比较特殊，它也是固定为某个应用服务的端口，但是它所代表的不是已经形成标准的应用层协议，而是某个软件厂商开发的应用程序，如CCProxy中的8080号端口。这类注册端口的端口号一般也都大于1024。
1）一开始，服务器应用层首先调用LISTEN原语从CLOSED状态进入被动打开状态（LISTEN），等待客户端的连接。2）当客户端的一个应用程序调用CONNECT原语后，本地的TCP实体为其创建一个连接记录并标记为SYN SENT状态，然后给服务器发送一个SYN数据段（SYN字段置1）。这是TCP传输连接的第一次握手。3）服务器在收到一个客户端的SYN数据段后，其TCP实体向客户端发送确认ACK数据段（ACK字段置1），同时发送一个SYN数据段（SYN字段置1，表示接受同步请求），进入SYN RCVD状态。这是TCP传输连接的第二次握手。4）客户端在收到服务器发来的SYN和ACK数据段后，其TCP实体给服务器端发送一个ACK数据段，并进入ESTABLISHED状态。这是TCP连接的第三次握手。5）服务器在收到来自客户端的ACK确认数据段后，完成整个TCP传输连接的全部三次握手过程，也进入ESTABLISHED状态。此时，双方可以自由进行数据传输了。当一个应用程序完成数据传输任务后，它需要关闭TCP连接。假设仍由客户端发起主动关闭连接。6）客户端应用层调用CLOSE原语，本地的TCP实体发送一个FIN数据段（FIN字段置1），并等待服务器的确认响应，进入FIN WAIT 1状态。7）服务器在收到来自客户端的FIN数据段后，它给客户端返回一个ACK数据段（ACK字段置1），进入CLOSE WAIT状态。8）客户端在收到来自服务器的ACK确认数据段后，进入FIN WAIT 2状态，此时连接在一个方向上就断开了，但仍可以接收服务器端发来的数据段。9）当服务器收到客户端发来的FIN数据段时就知道客户端已有数据发送了，在本端已接收完全部的数据后，也由应用层调用CLOSE原语，请求关闭另一个方向的连接，其本地TCP实体向客户端发送一个FIN数据段，并进入LAST ACK状态，等待最后一个ACK确认数据段。10）在客户端收到来自服务器的FIN数据段后，向服务器发送最后一个ACK确认数据段，进入TIMED WAIT状态。此时，双方连接均已经断开，但TCP实体仍要等待一个2倍数据段MSL（Maximum Segment Lifetime，最大数据段生存时间），以确保该连接的所有分组全部消失，防止出现确认丢失的情况。当定时器超时后，TCP删除该连接记录，返回到初始状态（CLOSED）。11）服务器收到客户端最后一个ACK确认数据段后，其TCP实体便释放该连接，并删除连接记录，也返回到初始状态（CLOSED）。
TCP/IP体系结构中的TCP也是使用三次握手机制来建立传输连接的，这与在本章前面介绍的OSI/RM体系结构中传输层为了避免重复连接而采取的三次握手机制是一样的
对TCP传输连接建立的三次握手过程来说，TCP传输连接的释放过程要稍微复杂一些，需要经过四次握手过程。这是由TCP的半关闭（half-close）特性造成的，因为这一个TCP连接是全双工（即数据在两个方向上能同时传递），每个方向必须单独进行关闭。TCP传输连接关闭的原则如下：当一端完成它的数据发送任务后就可以发送一个FIN字段置1的数据段来终止这个方向的数据发送；当另一端收到这个FIN数据段后，必须通知它的应用层“对端已经终止了那个方向的数据传送”。而FIN数据段的发送是由应用层调用CLOSE服务原语的结果。
在TCP可靠传输方面，主要采用以下4种机制：一是“字节编号机制”。TCP数据段以字节为单位对数据段中的“数据”部分进行一一编号，确保每个字节的数据都可以有序传送和接收。二是“数据段确认机制”。TCP要求每接收一个数据段都必须由接收端向发送端返回一个确认数据段（可以用一个确认数据段一次确认前面多个数据段），其中的“确认号”表明了接收端已正确接收的数据段序号（“确认号”前面的所有数据段）。三是“超时重传机制”。在TCP中有一个重传定时器（RetransmissionTimer，RTT），在发送一个数据段的同时也启动了该定时器。如果在定时器过期之前该数据段还没有被对方确认的话，则定时器停止，然后重传对应序号的数据段。四是“选择性确认（Selective ACK，SACK）机制”。在SACK支持下，仅可以重传缺少部分的数据，而不会重传那些已正确接收的数据。
“超时重传”是TCP保证数据可靠性的另一个重要机制，其原理是在发送某一个数据段以后就开启一个超时重传计时器（RetransmissionTimer，RTT）。如果在这个定时器时间内没有收到来自对方的某个数据段的确认，发送端启动重传机制，重新发送对应的数据段，直到发送成功为止。需要注意的是，并不是RTT定时器一到，就会立即重传数据，毕竟从“发送窗口”缓存中找到对应的数据段，然后安排重新发送都是需要时间的，实际上，超时重发的时间间隔（Retransmission Time Out）要大于RTT值。
TCP的流量控制是采用滑动窗口协议来进行的。而在本章前面已提到过，TCP数据段是以字节为单位进行编号的，但由于一个数据段只有一个TCP头部，所以TCP是以数据段为单位进行传输的，接收端通过TCP头部来识别所接收的数据属于哪个数据段。一个数据段只要没有完全接收，接收端就不会认为已接收了该数据段，就像我们平时通过QQ等工具传输文件时，只要还有部分没接收完，则我们的计算机就不会认为该文件已正确接收，即使已有了文件名，也打不开已接收的部分。
Nagle算法规定：如果数据每次以1字节的方式进入到发送端，则发送端只是发送第一个字节，然后其余的字节先缓存起来，直到发送出去的那个字节被确认为止。然后，将所有缓存起来的数据放在一个TCP数据段中发送出去，随后继续开始缓存后续字节，直到全部发送出去的字节全部确认为止。利用这种算法，可以大大提高传输效率，因为不会因1个字节而使用几十个协议头来携带。试想一下，例如，一个用户的键盘输入很快，而网络很慢，这时就会把用户的许多次输入字符组装成一个数据段，然后一次发送出去，大大减少所占用的网络带宽。Nagle算法还规定，当到达的数据已达到发送窗口大小的一半或者已达到数据段的最大长度时，也要发送出去。
为了解决这种问题，Clark提出了一种解决方案，就是禁止接收端发送“窗口大小”字段值为1（也就是数据部分仅1字节）的数据段，即让接收端继续等待一段时间，使得接收端的“接收窗口”有足够的空间可以容纳一个最大数据段长度的数据，或者它的缓存空间一半已空时（取两者的最小值）才发送确认数据段。这时，“窗口大小”字段值肯定不是1了，这样发送端就可以一次性发送更多的数据，从而提高传输效率。
TCP中最复杂的功能可能就是拥塞控制功能了，因为两端经过的网络数量、网络类型、网络性能非常不确定，而这些因素又深深地影响着TCP连接拥塞控制的复杂性和难度。
拥塞控制（congestion control）就是要控制“网络拥塞”的出现。什么情况下会出现网络拥塞呢？简单地说，网络中各个部分输入的流量大于输出的流量时就会出现网络拥塞。打一个比较类似的比喻（之所以说是“类似”，因为它更像“流量控制”类的比喻），就像在公路上发生塞车的一个根本原因就是出口道路太窄，而入口道路又比较宽，导致同一时间驶入的车辆数大于驶出的车辆数，最终使得这条路上排队并挤满了各种车辆，车辆的行驶速度自然会降下来
慢启动是指为了避免出现网络拥塞而采取的一种TCP拥塞初期预防方案。其基本思想就是在TCP连接正式传输数据时，每次可发送的数据大小（这就是“拥塞窗口”的含义）是逐渐增大的，也就是先发送一些小字节数的试探性数据，在收到这些数据段的确认后，再慢慢增加发送的数据量，直到达到了某个原先设定的极限值（也就是下面将要提到的“慢启动阈值”（SSTHRESH））为止。
UDP是一种无连接传输层协议，不像TCP那样需要服务器监听，也不必等待客户端与服务器建立连接后才能通信，当然，最后能否把数据传输成功，UDP是不能保证的。
（1）无连接性UDP可以提供无连接的数据报服务，这也决定了在使用UDP进行数据传输前是不需要建立专门的传输连接的，当然，在数据发送结束时也无须释放连接了。
2）不可靠性因为UDP传输数据时是不需要事先建立专门的传输连接的，所以它的传输是不可靠的（但会尽最大努力进行交付），很可能传输不成功。UDP特别适用于一些短消息类的数据传输，如DHCP、DNS中的一些消息就是采用UDP进行传输的。
3）以报文为边界UDP直接对应用层提交的报文进行封装、传输，但不拆分，也不合并，保留原来报文的边界。因此，UDP是报文流，而TCP是字节流。因为UDP不拆分报文，自然也就没有报文段之说，但UDP报文传输到网络层后，在网络层仍然可以根据网络的MTU值进行分割。
4）无流量控制和拥塞控制功能使用UDP进行数据传输时不能进行流量控制和拥塞控制，因为这类数据传输的连续性要比数据的完整性更重要，允许数据在传输过程中有部分丢失，如IP电话、流媒体通信等。
5）支持各种交互通信方式TCP不支持组播、广播通信方式，只支持一对一的单播方式，但UDP支持各种通信方式，即可以是一对一、一对多、多对一和多对多的方式。
第十一章应用层
1）迭代服务器（iterative server）方案在迭代服务器解决方案中，服务器程序中包含一个请求队列，客户请求到达后首先进入队列中等待，服务器按照先进先出的原则对这些客户端请求一个个做出响应，即服务器只有处理完前一个请求后才会处理下一个请求。（2）并发服务器（concurrent server）方案并发服务器是一个守护进程，在没有请求到达时它处于等待状态。一旦客户端请求到达，服务器立即再为之创建一个子进程，然后回到等待状态，由子进程响应请求。当下一个子进程到达时，服务器再为之创建一个子进程。其中，并发服务器称做主服务器，子进程称做从服务器。
在万维网中，存在3种全球统一标识，分别是URL（Uniform Resoure Locator，统一资源定位器）、URI（Uniform Resource Identifier，统一资源标识符）和URN（Uniform Resource Name，统一资源名称）
CGI是一种基于浏览器的输入，并可在Web服务器上运行应用程序（统称CGI程序）的方法。它允许Web服务器与后端程序及脚本进行通信，同时后端程序和脚本又可接收用户的输入信息（主要是来自表单），最后还能以HTML页面作为用户进行表单提交后的响应，如图11-3所示，具体描述如下（注意其中的序号与步骤是对应的）。1）用户在网站上单击了某项应用（如单击购买一个商品）后，相当于向Web服务器提交了一个表单。2）Web服务器在收到用户提交的表单后，会通过在服务器程序设计中已设置好的关联功能，把这个表单传送给对应的应用程序（也就是CGI程序）。3）CGI程序接收用户提交的表单，并对其进行处理（其中可能需要调用其他服务器，或者客户主机，如各种数据库存服务器），然后通过CGI程序的动态HTML文档生成功能，把处理结果以一个自动生成的HTML返回到Web服务器。4）Web服务器再把这个自动生成的HTML回显到Web用户的浏览器上。
HTTP具有以下几方面的特性：（1）客户端/服务器（C/S）模式C/S模式是所有网络应用服务采用的通用模式。Web客户只需要使用支持HTTP的客户端程序（各种浏览器），就可以访问由不同Web服务器程序开发的Web网站。（2）无连接这里所说的“无连接”是指在进行Web应用前无须建立专门的HTTP应用层会话连接，仅需要直接利用传输层已为它建立好的TCP传输连接即可，而像Telnet、SMTP、POP3这类应用协议，是面向连接的，除了需要传输层的TCP连接外，它们自己还要建立会话连接。（3）高可靠性虽然HTTP本身是不可靠的无连接协议，但它使用了可靠的TCP传输层协议，在进行HTTP传输之前，已建立了可靠的TCP连接，因此，从数据传输角度来讲，HTTP的报文传输仍是可靠的。（4）无状态这里所说“无状态”是指同一客户第二次访问同一Web服务器上的同一页面时，服务器给客户端的响应与第一次是一样的（当然，这是假设Web服务器上的对应页面没有更新），Web服务器不会记住这个客户端曾经访问过这个页面，而做出任何其他响应。（5）简单快速客户端通过HTTP访问Web服务器时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST等（具体内容将在本章后面介绍），每种方法规定了客户端与服务器之间进行的事务处理和消息类型。
一个HTTP请求报文包括请求行（request line）、请求头部（request header）行、空行和实体主体（entity body）行4个部分，如图11-5所示。HTTP报文（HTTP请求报文和11.2.9节将要介绍的HTTP响应报文）中各字段是没有固定长度的。
HTTP请求报文中的“请求行”是由“请求方法”、“URL”和“协议版本”3个字段组成的，它们之间均以空格进行分隔。“请求方法”字段指示本请求报文中所使用的HTTP操作（其实就是指所使用的HTTP命令），具体如表11-2所示（注意，全是大写字母，不能为小写）。
HTTP请求头部包括一系列的“请求头”和它们所对应的值，指出允许客户端向服务器传递请求的附加信息以及客户端自身的信息。当打开一个网页时，浏览器要向网站服务器发送一个HTTP请求头，然后网站服务器根据HTTP请求头的内容生成当次请求的内容并发送给浏览器，这就是HTTP请求报文中的“请求头”的作用。
在HTTP请求报文的最后一个请求头后是一个空行，发送回车符和换行符（一起以“CRLF”表示），通知服务器以下不再有请求头。
请求报文中“实体主体”部分通常是不用的。它不能在GET方法中使用，仅在POST方法中用于向服务器提供一些用户凭据信息。
在HTTP响应报文的“响应行”中主要有3个字段，分别是“协议版本”、“状态码”和“描述短语”，它们之间用空格分隔。最后还有一个回车控制符和一个换行控制符（一起用“CRLF”表示）。其中“协议版本”字段用来显示Web服务器使用的HTTP版本。“状态码”字段比较重要。它用一个3位数表示不同的状态，如请求是否被接受，如果没有被接受原因是什么，共有5组取值，如表11-4所示。“描述短语”字段是对应状态码的简短描述。
HTTP响应报文中的“响应头部行”允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和对URI所标识的资源进行下一步访问的信息。
DNS（Domain Name System，域名系统）是一种把计算机主机名称解析为对应的IP地址的服务。在UNIX和Linux操作系统中的DNS服务通常称为BIND（Berkeley InternetName Domain Service，伯克利因特网名称域服务）。
在应用层要访问目的主机时，不仅要指出该目的主机的网络层IP地址（用于网络寻址），还要指出在传输连接中使用的端口号，以及在应用层使用的应用协议。
（1）不便记忆尽管现在把IP地址以比较简单的十进制表示，在浏览器地址栏中也是以十进制格式表示IP地址的，其长度也不是很长（十进制IPv4地址最长也仅为12位），但是它远没有普通的名称好记，就像要记一个人的身份证号要远比记一个人的名字困难一样，哪怕身份证号只有短短的几位。
2）不方便地址变更Web服务器，特别是互联网上Web服务器的IP地址可能会因各种原因而变更。如果采用IP地址进行标识的话，那么IP地址的每次变更对于这种开放型的互联网服务器来说可能是致命的打击，因为有那么多已知或未知的用户，不可能一一都通知到。但如果采用的是网站服务器名称来进行标识，那么IP地址如何变化都没有影响，只要服务器主机名称不变即可。
（3）不安全如果直接把网站服务器的IP地址对外暴露，那么这显然不是一个安全的做法，因为这很可能被一些别有用心的人利用（窃取公网IP地址、盗链接等）。尽管对一些专业黑客来说，无论如何做好安全防范工作，要想获取服务器IP地址都是一件容易的事，但防范总好过不防范。
当一个应用进程需要把主机名解析为IP地址时，首先该应用程序就调用一个解析器（resolver），使它成为DNS客户，将该主机名作为DNS请求报文参数，以UDP用户数据报方式发送给本地DNS服务器。然后，本地DNS服务器查找该主机名，并且将找到的IP地址放在响应报文中返回给解析器。解析器再将IP地址返回给调用解析器的应用进程，这样应用进程就可以根据所得到的目的IP地址进行通信了。当然，可能会存在本地DNS服务器不能解析所请求的主机名的情况，这时本地DNS服务器就仅为一个DNS代理角色，然后它可以把这个解析工作交给在本地服务器上配置的其他相关联的DNS服务器。以上就是DNS服务器的“转发器”功能。
目前，计算机名主要有两种格式，一种是像早期host文件中那样的非分级的单一字符串所代表的本地计算机名称，如webserver；另一种是以DNS域名为基础的域网络中的DNS名称，如webserver.lycb.com，后面的“lycb.com”是一个域名。完整的DNS名称（webserver. lycb.com）代表的是在lycb.com域中的一台名为webserver的服务器。
DNS域名不是单一结构，而是包含至少两个层次的分级结构，因为单一结构的域名无法满足全球如此多互联网用户的需求，就像尽管没有限制姓名长度，而且汉字有上万个，但还是很难避免完全不重名。
在早期利用host文件保存计算机名到IP地址映射的解决方案中，网络中的名称解析工作全是由少数几个集中存储host文件的服务器主机来担当的。随着网络规模的不断扩大，这种完全集中的管理方式显然不能满足解析性能要求，在今天的互联网上更是不可能实现
前面介绍的DNS系统仅是从服务器命名角度来讲的一项技术，但真正担当DNS域名解析任务的还是那些配置了DNS服务的服务器，就是DNS服务器，专业名称为“名称服务器”（或者“域名服务器”）。在DNS名称服务器中，要特别注重两个方面：一是DNS服务器的分区管理，二是DNS服务器的不同类型以及它们之间的关系。
从理论上来说，每一级的每个DNS域名都需要配备一台专门用于名称解析的DNS名称服务器，但是全球有那么多域名，每个域名都专门配备的话，则互联网域名管理机构所需配备的DNS名称服务器就实在太多了，这明显不是一种有效的解决方案。
为了有效地管理整个互联网的DNS域名解析工作，DNS系统开发者设计了一个与分层的DNS域名结构类似的层次化DNS名称服务器结构，把所有DNS名称服务器自高到低分成4个级别：根名称服务器、顶级名称服务器、权威名称服务器和本地名称服务器。
根名称服务器”（root name server）是由互联网管理机构配置建立的，是最高层次的名称服务器，负责对互联网上所有“顶级名称服务器”进行管理，有全部的顶级名称服务器的IP地址和域名映射。
“顶级名称服务器”（top level name server）是各顶级域名自己的名称服务器，负责它们各自所管理的二级域名解析。每一个顶级域名，不论是gTLD（通用顶级域），还是ccTLD（国别顶级域），它们都有自己的域名服务器。如顶级域名com和net 有13台名称服务器，主机名也是A～M，域名为gtld-servers.net；顶级域名biz有6台名称服务器，主机名是A～H，域名为gtld.biz。
“权威名称服务器”（authoritative name server）是针对前面所说的DNS区域提供名称解析服务而专门配置、建立的名称服务器，可为用户提供最权威的DNS域名解析。每一个域名在互联网上都可找到一台权威名称服务器，ISP也可为用户的每一个DNS域名区域配置一台权威名称服务器。
这里所说的“本地名称服务器”不是指用户局域网中的名称服务器，而是用户端操作系统所配置的、由本地ISP提供的名称服务器（也就是本地DNS服务器）。它是离用户最近的互联网名称服务器。用户发出的DNS域名解析请求，首先到达的就是本地名称服务器。
DNS报文也分为两部分，一部分是报头部分，另一部分是数据部分。报头部分是固定的，有6个字段，共12字节大小，而数据部分由四大部分组成，且长度可变
DNS请求报文中的具体请求消息是在如图11-11所示的报文格式中“查询消息”部分显示的，包括对应DNS域名查询所请求的问题。
1）QName：表示所请求解析的域名，不过它显示的是一串ASCII编码，长度可变（注意，不是固定的16位）。在每个域名的开头以及中间的小圆点（.）部分均为一个十六进制数，表示下一节域名的ASCII字符数，后面是每节域名各个符号对应的ASCII字符（每个字母和符号均占1字节，即两位十六进制数字），在每个域名的最后均以一个字节的0（ 00）来表示。但要注意的是，这个字段的长度不是固定的，也可以为奇数个字节，不用填充。
2）QType：表示查询的资源记录类型，占2字节，是本节后面将要介绍的资源记录中的TYPE（类型）字段的扩展。表11-7中的TYPE类型字段值均是Qtype字段合法的取值（有些通用的QType值可以和多条资源记录相匹配），另外，还可以有以下取值。
DNS服务同样也是C/S工作模式，分为DNS服务器和DNS客户端。其中，DNS客户端以DNS请求报文向DNS服务器发出域名解析请求，DNS服务器以DNS应答报文对客户端的DNS请求做出应答。
DNS有两种名称解析方式：一种称为“递归解析”（RecursiveSolution，RS），另一种称为“迭代解析”（Iterative Solution，IS），也称“反复解析”。它们有不同的查询和应答流程：递归解析是一种代理查询方式，如果本地名称服务器不能解析，则后面的查询请求全由本地名称服务器代理DNS客户端进行查询，最终由本地名称服务器返回最后的解析结果；而迭代解析中的查询请求全由DNS客户端自己根据每次查询从上级DNS服务器上得到的信息依次查询下级DNS服务器。
“递归解析”（或称“递归查询”，其实意思是一样的）是最常见的默认的解析方式。在这种解析方式中，如果客户端配置的本地名称服务器不能解析的话，则后面的查询全由本地名称服务器代替DNS客户端进行查询，直到本地名称服务器从权威名称服务器得到了正确的解析结果，然后由本地名称服务器告诉DNS客户端查询的结果。
使用迭代解析方式时，如果它所配置的主名称服务器（如Windows操作系统中的“首选DNS服务器”）不能解析的话，那么客户端还会继续向所配置的其他名称服务器（如Windows操作系统中的“备用DNS服务器”）查询。迭代解析的基本流程如下。
1）客户端向本机配置的本地名称服务器（在此仅以首选DNS服务器为例进行介绍，其他备用DNS服务器的解析流程也完全一样）发出DNS域名查询请求。2）本地名称服务器收到请求后，先查询本地的缓存，如果有该域名的记录项，则本地名称服务器直接把查询的结果返回给客户端；如果本地缓存中没有该域名的记录，则向DNS客户端返回一条DNS应答报文，报文中会给出一些参考信息，如本地名称服务器上的根名称服务器地址等。3）DNS客户端在收到本地名称服务器的应答报文后，会根据其中的根名称服务器地址信息，向对应的根名称服务器再次发出与前面一样的DNS查询请求报文。4）根名称服务器在收到DNS查询请求报文后，通过查询自己的DNS数据库得到请求DNS域名中顶级域名所对应的顶级名称服务器信息，然后以一条DNS应答报文返回给DNS客户端。5）DNS客户端根据来自根名称服务器应答报文中的对应顶级名称服务器地址信息，向该顶级名称服务器发出与前面一样的DNS查询请求报文。6）顶级名称服务器在收到DNS查询请求后，先查询自己的缓存，如果有所请求的DNS域名的记录项，则把对应的记录项返回给DNS客户端，否则通过查询后把对应域名中二级域名所对应的二级名称服务器地址信息以一条DNS应答报文返回给DNS客户端。
1）DNS客户端向所配置的本地名称服务器dns.company.com发出解析example. microsoft.com域名的DNS请求报文（图11-16中的Q1）。2）本地名称服务器收到DNS客户端的DNS查询请求报文后，先查询本地缓存。如果没有查到该域名对应的记录，则本地名称服务器把所配置的根名称服务器a.rootserver.net地址信息以DNS应答报文返回给DNS客户端（图11-16中的A1）。3）DNS客户端在收到本地名称服务器的DNS应答报文后，根据其中给出的根名称服务器地址信息，向对应的根名称服务器再次发送解析example.microsoft.com域名的DNS请求报文（图11-16中的Q2）
4）根名称服务器在收到DNS查询请求后，通过查询得到.com顶级域名对应的顶级名称服务器，然后把查询到的对应顶级域名信息以一条DNS应答报文返回给DNS客户端（图11-16中的A2）。5）DNS客户端在收到根名称服务器的DNS应答报文，并得到.com顶级域名对应的顶级名称服务器地址后，再次向对应的顶级名称服务器发送一条解析example.microsoft.com域名的DNS请求报文（图11-16中的Q3）。6）.com顶级名称服务器在收到DNS客户端的DNS查询请求报文后，先查询自己的缓存，假设也没有该域名的记录项，则查询microsoft.com对应的二级名称服务器，然后把查询到的对应二级域名信息以一条DNS应答报文返回给DNS客户端（图11-16中的A3）。7）DNS客户端在收到.com顶级名称服务器的DNS应答报文，并得到microsoft.com二级域名对应的二级名称服务器地址后，再次向对应的二级名称服务器发送一条解析example. microsoft.com域名的DNS请求报文（图11-16中的Q4）。8）microsoft.com二级名称服务器在收到DNS客户端的DNS查询请求报文后，也先查询自己的缓存，如果也没有该域名的记录项，则查询example.microsoft.com对应的权威名称服务器（因为这个名称服务器已包括了整个域名example.microsoft.com所在区域），然后把查询到的对应权威域名信息以一条DNS应答报文返回给DNS客户端（图11-16中的A5）。9）DNS客户端在收到microsoft.com二级名称服务器的DNS应答报文，并得到example.microsoft.com三级域名对应的权威名称服务器地址后，再次向对应的权威名称服务器发送解析example.microsoft.com域名的DNS请求报文（图11-16中的Q5）。10）权威名称服务器在收到DNS客户端的DNS查询请求报文后，在它的DNS区域数据库中查找，最终会得出example.microsoft.com域名对应的IP地址，然后向DNS客户端返回一条DNS应答报文（图11-16中的A5）。这样DNS客户端就可以正常访问这个网站了。
DHCP（动态主机配置协议）是一种用于简化主机IP配置管理的服务。通过采用DHCP服务，可以使用DHCP服务器为网络上安装了DHCP服务客户端程序的客户端进行动态IP地址分配和其他相关设置，而不需要管理员对各个客户端进行一一配置，减轻了许多管理负担。
BOOTP有两个缺点：一是在为站点分配IP地址前，必须在服务器事先配置好对应站点的MAC地址，管理员的工作量比较大（主要是体现在事先必须收集各站点的MAC地址上）。二是BOOTP分配的IP地址是静态的，没有租约期的概念，即一个站点分配了一个IP地址后，可以永久使用这个IP地址，直到站点重启或关机。这样就形成了一个一对一的静态关系，不利于IP地址的有效使用。
DHCP服务之所以能为DHCP客户端自动分配IP地址，其根本原因是在DHCP服务器中已准备好了用来为客户端分配IP地址的IP地址池。这个IP地址池就像装满了可用于分配的许多IP地址的池子一样，而且这些IP地址是属于一个网段的一部分或者全部的IP地址。有关DHCP的IP地址分配原理将在本章后续部分介绍。
使用了DHCP服务后，安装了DHCP客户端程序（现在几乎所有操作系统都自带并安装了这一程序）的计算机可直接选择如图11-17所示的“自动获得IP地址”和“自动获得DNS服务器地址”选项，这样客户端就无须配置IP地址、子网掩码、网关、DNS服务器地址等TCP/IP信息。由此可见，DHCP服务可大大减轻管理员的工作负担（一般TCP/IP的配置是需要管理员权限的）。注意，由DHCP服务器自动分配的IP地址都有一个租约期，也就是自分配给某个客户端开始，该客户端只能在这个租约期内使用所分配的这个IP地址，但过期后可以续约，或者重新申请
使用DHCP服务自动为客户端分配IP地址还有一个好处就是方便客户端的移动，这对于需要移动办公的人来说非常实用，这样客户端连接在哪里就可以从对应网段（或VLAN）配置的DHCP服务器上自动分配对应网段的IP地址。反过来，如果采用的是静态IP地址分配方式，则客户端每次移动到一个其他网段（或VLAN），管理员都需要重新设置一次TCP/IP信息。
采用DHCP服务自动分配IP地址信息可以有效地避免由于配置时的输入错误而引起的配置错误，还有助于防止在网络上配置新的计算机时因重用以前指派的IP地址而引起的地址冲突。
整个DHCP服务一共有8种类型（主要是前面7种类型）的DHCP报文，分别为DHCP DISCOVER、DHCP OFFER、DHCP REQUEST、DHCPACK、DHCP NAK、DHCP RELEASE、DHCP DECLINE、DHCPINFORM。
虽然DHCP服务的报文类型比较多，但每种报文的格式基本相同，只是某些字段取值可能不同。DHCP报文格式基于BOOTP的报文格式，如图11-18所示。
1）发现阶段：即DHCP客户端获取网络中DHCP服务器信息的阶段。在客户端配置了DHCP客户端程序（如在Windows操作系统中进行了如图11-17所示的配置）并启动后，以广播方式发送DHCP DISCOVER报文寻找网络中的DHCP服务器。此广播报文采用传输层的UDP 68号端口发送（封装的目的端口为UDP 68号端口），经过网络层IP封装后，源IP地址为0.0.0.0（因为此时还没有分配IP地址），目的IP地址为255.255.255.255（有限广播IP地址）。下面是一个DHCP DISCOVER报文封装的IP报头示例，可以看到Destination Address（目的地址）是 255.255.255.255，而 SourceAddress（源地址）是 0.0.0.0。




















