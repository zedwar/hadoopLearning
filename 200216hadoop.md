##第一篇Hadoop基础知识
###第一章初识Hadoop
    大数据技术是发现大规模数据中的规律，通过对数据的分析实现对运营层决策的支持
    大数据的特点可以用“4v”来表示，分别为volume、variety、velocity和value
    批处理计算又称为离线计算，是针对大规模历史数据的批量处理，如MapReduce。
    ·流计算是针对流数据的实时计算，可以实时处理产生的数据。商业版的有IBM InfoSphere Streams和IBM StreamBase，开源的有Storm和
        S4（Simple Scalable Streaming System），还有一部分是企业根据自身需求而定制的，如Dstream（百度）。
    ·图计算是针对大规模图结构数据的处理，常用于社交网络，如Pregel、GraphX、Giraph（FaceBook）、PowerGraph和Hama等。
    ·查询分析计算是针对大规模数据的存储管理和查询分析，如Hive、Cassandra和Impala等。
###第二章
    略
###第三章hadoop介绍
    分布式文件系统DFS是基于Master/Slave模式，通常一个分布式文件系统提供多个供用户访问的服务器，一般都会提供备份和容错的功能。
        分布式文件系统管理的物理资源不一定直接连接在本地节点上，而是通过计算机网络与节点相连，而非文件系统管理的物理存储资源一定
        直接连在本地节点上。    
    HDFS是Hadoop自带的分布式文件系统，即Hadoop Distributed FileSystem。HDFS是一个使用Java语言实现的分布式、可横向扩展的文件系统。
    HDFS的设计主要是为了实现存储大量数据、成本低廉和容错率高、数据一致性，以及顺序访问数据这4个目标
    ·高容错性：数据自动保存多个副本，副本丢失后自动恢复。·适合批处理：移动计算而非数据，数据位置暴露给计算机框架。
        ·适合大数据处理：GB、TB，甚至PB级数据，百万规模以上的文件数量，10k+节点。·可构建在廉价机器上：通过副本提高可靠性，提供了容错和恢复机制
    客户端传入文件读写请求时，NameNode（HDFS的集群管理节点）首先接受客户端的读写服务请求，并根据它保存的Metadata元数据，包括元数
        据的镜像文件（fsimage和操作日志edits信息）和DataNode（数据存储）通信并进行资源协调，Secondary NameNode进行edits和fsimage的合并，同时DataNode之间进行数据复制
    HDFS的核心概念：1．数据块（block）每个磁盘都有默认的数据块大小，这是磁盘进行数据读/写的最小单位。HDFS也有块的概念
        2．NameNodeNameNode为HDFS集群的管理节点，一个集群通常只有一台活动的NameNode，它存放了HDFS的元数据且一个集群只有一份元数据。
        3．DataNodeDataNode中文件的储存方式是按大小分成若干个Block，存储到不同的节点上，Block大小和副本数通过Client端上传文件时设
        置，文件上传成功后副本数可以变更，BlockSize不可变更。默认情况下每个Block都有3个副本。
        4．SecondaryNameNodeSecondaryNameNode（简称SNN），它的主要工作是帮助NameNode合并edits，减少NameNode启动时间
        5．元数据元数据保存在NameNode的内存中，以便快速查询，主要包括fsimage和edits。
    通过客户端发送读文件请求，主要步骤如下：（1）客户端通过调用FileSystem对象的open()方法打开要读取的文件，对于HDFS来说，这个对
        象是DistributedFileSystem的一个实例。（2）DistributedFileSystem通过使用远程过程调用（RPC）来调用NameNode，以确定文件起
        始块的位置。（3）对于每个块，NameNode返回到存有该块副本的DataNode地址。此外，这些DataNode根据它们与客户端的距离来排序。
        如果该客户端本身就是一个DataNode，那么该客户端将会从包含有相应数据块副本的本地DataNode读取数据。DistributedFileSystem类
        返回一个FSDataInputStream对象给客户端并读取数据，FSDataInputStream转而封装DFSInputStream对象，该对象管理着DataNode和
        NameNode的I/O。接着，客户端对这个输入流调用read()方法。（4）存储着文件起始几个块的DataNode地址的DFSInputStream，接着会
        连接距离最近的文件中第一个块所在的DataNode。通过对数据流的反复调用read()方法，实现将数据从DataNode传输到客户端。（5）当
        快到达块的末端时，DFSInputStream会关闭与该DataNode的连接，然后寻找下一个块最佳的DataNode。（6）当客户端从流中读取数据时
        ，块是按照打开的DFSInputStream与DataNode新建连接的顺序进行读取的。它也会根据需要询问NameNode从而检索下一批数据块的DataNode
        的位置。一旦客户端完成读取，就对FSDataInputStream调用close()方法    
    存储在HDFS上的文件也可以写入内容，可以通过客户端发送写文件的请求，主要步骤如下：（1）客户端调用DistributedFileSystem对象的
        create()方法新建文件。（2）DistributedFileSystem会对NameNode创建一个RPC调用，在文件系统的命名空间中创建一个新文件，需
        要注意的是，此刻该文件中还没有相应的数据块。（3）NameNode通过执行不同的检查来确保这个文件不存在而且客户端有新建该文件的权
        限。如果这些检查都通过了，NameNode就会为创建新文件写下一条记录；反之，如果文件创建失败，则向客户端抛出一个IOException异
        常。（4）随后DistributedFileSystem向客户端返回一个FSDataOutputStream对象，这样客户端就可以写入数据了。和读取事件类似，
        FSDataOutputStream封装一个DFSOutputStream对象，该对象会负责处理DataNode和NameNode之间的通信。在客户端写入数据的时候，
        DFSOutputStream将它分成一个个的数据包，并且写入内部队列，被称之为“数据队列”（data queue）。（5）DataStream处理数据队列，
        它的任务是选出适合用来存储数据副本的一组DataNode，并据此要求NameNode分配新的数据块。这一组DataNode会构成一条管线，
        DataStream会将数据包流式传输到管线中的第一个DataNode，然后依次存储并发送给下一个DataNode。（6）DFSOutPutStream也维护着
        一个内部数据包队列来等待DataNode的收到确认回执，称为“确认队列”（ask queue）。收到管道中所有DataNode确认信息后，该数据包
        才会从确认队列删除。（7）客户端完成数据的写入后，会对数据流调用close()方法
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
        